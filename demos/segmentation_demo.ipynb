{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Imports.\n",
    "import os\n",
    "\n",
    "projectdir = '/Users/michielkleinnijenhuis'\n",
    "dataset = 'HFK16w'\n",
    "\n",
    "datadir = os.path.join(projectdir, dataset)\n",
    "\n",
    "os.makedirs(datadir, exist_ok=True)\n",
    "os.chdir(datadir)\n",
    "f'working in directory: {os.path.abspath(\".\")}'\n",
    "\n",
    "parameter_file = f'{dataset}.yml'\n",
    "ims_filepath = f'{dataset}_shading_stitching.ims'  # f'{dataset}_shading_stitching_biasfield.ims'\n",
    "image_in = ims_filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.segmentation import zipping\n",
    "from importlib import reload\n",
    "reload(zipping)\n",
    "zipp3r = zipping.Zipp3r(image_in, parameter_file, prefix=dataset)  # parameter file for segmentation hook\n",
    "zipp3r.ids_labels = 'segm/labels_raw'\n",
    "zipp3r.relabel()\n",
    "zipp3r.estimate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.view([0], images=['memb/prep'], labels=['segm/labels_raw', 'segm/labels_zip'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axlab = 'zyx'\n",
    "\n",
    "zipp3r.margin = 64\n",
    "zipp3r.n = {'z': 3, 'y': 3, 'x': 3}\n",
    "# zipp3r.n = {'z': 2, 'y': 2, 'x': 2}\n",
    "# zipp3r.n = {'z': 1, 'y': 1, 'x': 1}\n",
    "\n",
    "zipp3r.zipstep = 'q'\n",
    "zipp3r._axis = 0\n",
    "zipp3r.zipstep = 'y'\n",
    "zipp3r._axis = 1\n",
    "zipp3r.zipstep = 'x'\n",
    "zipp3r._axis = 2\n",
    "\n",
    "zipp3r._set_blockmap(axislabels=axlab)\n",
    "\n",
    "seam_idx = 0\n",
    "seam_pairs = zipp3r.get_seam_pairs(seam_idx)\n",
    "pairs = {i: pair for i, pair in enumerate(seam_pairs)}\n",
    "pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembled block\n",
    "\n",
    "from stapl3d.segmentation import zipping\n",
    "from importlib import reload\n",
    "reload(zipping)\n",
    "\n",
    "ids = 'segm/labels_zip'\n",
    "\n",
    "blockpair = [zipp3r._blocks[i] for i in pairs[0]]\n",
    "\n",
    "blockset = zipping.Zipset(blockpair, zipp3r.zipstep, zipp3r.n)\n",
    "\n",
    "blockset.read_margins(ids, imtype='Label')\n",
    "blockset.assemble_dataset(ids, 'Label')\n",
    "blockset.write_margins(ids)\n",
    "\n",
    "# labelsets = zipp3r.get_boundary_labels(blockset)\n",
    "# blockset.blocks[1].datasets[ods_labels].image.maxlabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def _get_nmax(blocks, axis, margin, n_cap=10):\n",
    "    \"\"\"Calculate how many margin-blocks fit into the dataset.\"\"\"\n",
    "\n",
    "    sizes = []\n",
    "    for al in 'zyx':  # TODO: 'zyx'\n",
    "        for block in blocks:\n",
    "            size = block.slices_region[al].stop - block.slices_region[al].start\n",
    "            sizes.append(size)\n",
    "\n",
    "        n_max = int(np.amin(np.array(sizes)) / margin)\n",
    "\n",
    "    # TODO: change to variable size over dimensions\n",
    "    #blockmargin = np.array([self.blockmargin[al] for al in 'zyx'])\n",
    "#        n_max = np.array(np.array(sizes) / blockmargin, dtype='int')\n",
    "    # n_max = np.minimum(np.array([n_cap]*3), n_max)\n",
    "\n",
    "    n_max = int(np.amin(np.array(sizes)) / margin)\n",
    "    n_max = min(n_cap, n_max)\n",
    "\n",
    "    return n_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_get_nmax(blockset.blocks, axis=0, zipp3r.blockmargin, n_cap=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = blockset.blocks[1]\n",
    "\n",
    "for al in zipp3r._axlab:\n",
    "    if zipp3r.blockmargin[al]:\n",
    "        n = int(block.shape[al] / zipp3r.blockmargin[al])\n",
    "    else:\n",
    "        n = 1\n",
    "    print(al, n)\n",
    "\n",
    "# block.datasets[ids].slices_blockfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capped = {al: False for al in 'zyx'}\n",
    "all(capped.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = {}\n",
    "for al in 'zyx':\n",
    "    sizes = []\n",
    "    for block in blockset.blocks:\n",
    "        size = block.slices_region[al].stop - block.slices_region[al].start\n",
    "        sizes.append(size)\n",
    "    if zipp3r.blockmargin[al]:\n",
    "        n_max[al] = int(block.shape[al] / zipp3r.blockmargin[al])\n",
    "    else:\n",
    "        n_max[al] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockset_slices = blockset._get_slices(include_margin=False)\n",
    "block = blockset.blocks[1]\n",
    "slices = blockset_slices[1]\n",
    "imtype = 'Label'\n",
    "# blockset.read_margins(ids, imtype='Label')\n",
    "\n",
    "props = dict(axlab=axlab, imtype=imtype, slices=slices)  # FIXME: dtype , dtype='int'\n",
    "block.create_dataset(ids, **props)\n",
    "block.path\n",
    "block.datasets[ids].path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block = blockset.blocks[1]\n",
    "block.create_dataset(ids)\n",
    "block.datasets[ids].path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for al in axlab:\n",
    "    slc = slice(\n",
    "        blockset.full2block(block, al, slices[al].start),\n",
    "        blockset.full2block(block, al, slices[al].stop),\n",
    "    )\n",
    "    block.datasets[ids].slices_blockfile[al] = slc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_labels = 'segm/labels_zip'\n",
    "axlab = 'zyx'\n",
    "for block, labelset in zip(blockset.blocks, labelsets):\n",
    "    seg = block.datasets[ods_labels].image\n",
    "    fw_map = [True if l in labelset else False for l in range(0, seg.maxlabel + 1)]\n",
    "    mask = np.array(fw_map)[seg.ds]\n",
    "\n",
    "    block.create_dataset('mask', axlab=axlab)\n",
    "    block_ds_in = block.datasets['mask']\n",
    "    block_ds_in.dtype = mask.dtype\n",
    "    block_ds_in.create_image(data=mask)\n",
    "    block_ds_in.image.ds[:] = mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg.maxlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(labelsets[1])\n",
    "zipp3r.create_resegmentation_mask(blockset, labelsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idss = {'mean': 'Image', 'memb/mean': 'Image'}\n",
    "for ids, imtype in idss.items():\n",
    "    blockset.read_margins(ids, imtype='Image')\n",
    "    blockset.assemble_dataset(ids, imtype='Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block.datasets['mean'].image.ds.shape\n",
    "block.datasets['memb/mean'].image.ds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d import blocks\n",
    "splitt3r = blocks.Splitt3r(image_in, parameter_file, prefix=dataset)\n",
    "splitt3r.run()\n",
    "\n",
    "ims_filepath = f'{dataset}_shading_stitching.ims'  # f'{dataset}_shading_stitching_biasfield.ims'\n",
    "image_in = ims_filepath\n",
    "\n",
    "max_workers = 5  # NB: ACME is memory-intensive\n",
    "\n",
    "from stapl3d.segmentation import enhance\n",
    "enhanc3r = enhance.Enhanc3r(image_in, parameter_file, prefix=dataset, max_workers=max_workers)\n",
    "enhanc3r.ACMEdir = os.environ.get('ACME')\n",
    "\n",
    "if enhanc3r.ACMEdir:\n",
    "\n",
    "    # Perform membrane enhancement.\n",
    "    enhanc3r.run()\n",
    "\n",
    "else:\n",
    "\n",
    "    acme_filepath = f'{dataset}_shading_stitching_ACME.h5'\n",
    "\n",
    "    # Download precomputed membrane enhancement.\n",
    "    if not os.path.exists(acme_filepath):\n",
    "        url = 'https://surfdrive.surf.nl/files/index.php/s/oQcxIocFBkaXwJe/download'\n",
    "        urllib.request.urlretrieve(url, acme_filepath)\n",
    "\n",
    "    # Split into blocks\n",
    "    from stapl3d import blocks\n",
    "    for ids in ['memb/preprocess', 'memb/planarity']:\n",
    "        filepath_in = f'{acme_filepath}/{ids}'\n",
    "        splitt3r = blocks.Splitt3r(filepath_in, parameter_file, prefix=dataset)\n",
    "        splitt3r.volumes = {ids: {'output_ND': True}}  # override volumes from parameter file\n",
    "        splitt3r.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  segmentation:blockinfo in 64 jobs over 16 workers\n",
      "Running  segmentation:estimate in 64 jobs over 16 workers\n",
      "prep_dset took 3.278795 s for block B00007\n",
      "prep_dset took 3.396240 s for block B00000\n",
      "prep_dset took 3.946743 s for block B00002\n",
      "prep_dset took 4.041285 s for block B00005\n",
      "prep_dset took 4.006826 s for block B00006\n",
      "prep_dset took 4.051975 s for block B00004\n",
      "prep_dset took 4.101120 s for block B00008\n",
      "prep_dset took 4.017288 s for block B00001\n",
      "prep_dset took 4.038206 s for block B00015\n",
      "prep_dset took 4.124699 s for block B00003\n",
      "prep_dset took 4.828738 s for block B00010\n",
      "prep_dset took 4.851858 s for block B00014\n",
      "prep_dset took 4.906778 s for block B00012\n",
      "prep_dset took 4.959867 s for block B00009\n",
      "prep_dset took 4.956201 s for block B00013\n",
      "prep_dset took 5.050965 s for block B00011\n",
      "prep_dset took 3.734333 s for block B00016\n",
      "prep_dset took 3.530109 s for block B00023\n",
      "prep_dset took 3.832383 s for block B00024\n",
      "prep_dset took 4.668385 s for block B00017\n",
      "prep_dset took 4.214167 s for block B00025\n",
      "prep_dset took 4.618515 s for block B00018\n",
      "prep_dset took 3.620997 s for block B00031\n",
      "prep_dset took 4.700430 s for block B00019\n",
      "prep_dset took 4.699281 s for block B00020\n",
      "prep_dset took 4.712277 s for block B00022\n",
      "prep_dset took 4.748856 s for block B00021\n",
      "prep_dset took 4.528093 s for block B00026\n",
      "prep_dset took 4.531331 s for block B00027\n",
      "prep_dset took 4.553207 s for block B00028\n",
      "prep_dset took 4.588623 s for block B00030\n",
      "prep_dset took 4.690572 s for block B00029\n",
      "prep_dset took 3.955164 s for block B00032\n",
      "prep_dset took 3.834575 s for block B00040\n",
      "prep_dset took 3.853244 s for block B00039\n",
      "prep_dset took 4.988129 s for block B00033\n",
      "prep_dset took 4.922046 s for block B00035\n",
      "prep_dset took 5.090929 s for block B00034\n",
      "prep_dset took 4.959659 s for block B00036\n",
      "prep_dset took 4.844741 s for block B00037\n",
      "prep_dset took 3.759488 s for block B00047\n",
      "prep_dset took 4.813078 s for block B00038\n",
      "prep_dset took 4.758610 s for block B00041\n",
      "prep_dset took 4.951046 s for block B00042\n",
      "prep_dset took 4.820731 s for block B00044\n",
      "prep_dset took 4.882485 s for block B00043\n",
      "prep_dset took 4.811574 s for block B00045\n",
      "prep_dset took 4.763264 s for block B00046\n",
      "prep_dset took 3.511255 s for block B00048\n",
      "prep_dset took 2.751211 s for block B00056\n",
      "prep_dset took 4.251750 s for block B00049\n",
      "prep_dset took 3.276942 s for block B00058\n",
      "prep_dset took 4.306854 s for block B00050\n",
      "prep_dset took 3.370418 s for block B00057\n",
      "prep_dset took 3.597618 s for block B00055\n",
      "prep_dset took 4.367394 s for block B00051\n",
      "prep_dset took 3.331541 s for block B00059\n",
      "prep_dset took 2.749025 s for block B00063\n",
      "prep_dset took 4.352859 s for block B00052\n",
      "prep_dset took 4.058862 s for block B00054\n",
      "prep_dset took 4.339587 s for block B00053\n",
      "prep_dset took 3.182751 s for block B00060\n",
      "prep_dset took 3.211506 s for block B00061\n",
      "prep_dset took 3.218220 s for block B00062\n",
      "Running  segmentation:postprocess in 1 jobs over 1 workers\n",
      "WARNING: files could not be merged: no inputfiles specified\n"
     ]
    }
   ],
   "source": [
    "from stapl3d.segmentation import segment\n",
    "segment3r = segment.Segment3r(image_in, parameter_file, prefix=dataset)\n",
    "segment3r.run()\n",
    "# segment3r.view([2], images=['memb/mean'], labels=['segm/labels_raw'])  # , 'segm/labels', 'segm/labels_zip'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment3r.view([2], images=['memb/mean', 'memb/norm'], labels=['segm/labels_raw'])  # , 'segm/labels', 'segm/labels_zip'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "block.create_dataset(ids, axlab=axlab)\n",
    "block_ds_in = block.datasets[ids]\n",
    "block_ds_in.dtype = data.dtype\n",
    "block_ds_in.create_image(data=data)\n",
    "block_ds_in.image.ds[:] = data\n",
    "\n",
    "# Resegment the block.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockset.slices_read, blockset.slices_write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write assembled block to blockset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zipsels = self._get_zipsels(len(blocks))\n",
    "# for block, zipsel in zip(blocks, zipsels):\n",
    "\n",
    "#     # Slice the margin from the concatenated block.\n",
    "#     concat_slices = self._get_slices_concat(zipsel, axlab)\n",
    "#     data_block = data[tuple(concat_slices.values())]\n",
    "\n",
    "#     # slices = self._get_write_slices(block, zipsel, axlab)\n",
    "#     slices = block._get_zip_slices(zipsel, self.n, axlab, include_margin=True)\n",
    "\n",
    "#     block.create_dataset(ids, axlab=axlab, imtype=imtype)\n",
    "#     block_ds = block.datasets[ids]\n",
    "#     block_ds.dtype = 'int'\n",
    "#     block_ds.create_image(f'{block.path}/{ids}')\n",
    "#     block_ds.image.load()\n",
    "\n",
    "#     for al in axlab:\n",
    "#         slc = slice(\n",
    "#             full2block(block, al, slices[al].start),\n",
    "#             full2block(block, al, slices[al].stop),\n",
    "#         )\n",
    "#         dim = block_ds.image.axlab.index(al)\n",
    "#         block_ds.image.slices[dim] = slc\n",
    "\n",
    "#     update_vol(block_ds.image, data_block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape, block.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# im = block_ds_in.image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(zipp3r._blocks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = zipp3r.ods_labels\n",
    "axlab = 'zyx'\n",
    "imtype = 'Label'\n",
    "block = zipp3r._blocks[0]\n",
    "block.create_dataset(ids, axlab=axlab, imtype=imtype)\n",
    "block_ds = block.datasets[ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ds.dtype = 'int'\n",
    "ds_path = f'{block.path}/{ids}'\n",
    "block_ds.create_image(path=ds_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ds.image.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ds.image.ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ds.image.slices\n",
    "block_ds.image.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.blockmargin\n",
    "axlab = 'zyx'\n",
    "zipsels = zipp3r._get_zipsels(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axlab='zyx'\n",
    "slices = zipp3r._get_slices_boundaries(zipsels[0], axlab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = {al: slice(None) for al in axlab}\n",
    "for al, upper in zipsel.items():\n",
    "\n",
    "    include_margin = False\n",
    "    margin = self.blockmargin[al]\n",
    "    b = margin if include_margin else 1\n",
    "    slice_selector = {True: slice(-b, None), False: slice(None, b)}\n",
    "\n",
    "    slices[al] = slice_selector[upper]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.margin = 64\n",
    "zipp3r.n = 1\n",
    "\n",
    "zipp3r.zipstep = 'q'\n",
    "zipp3r._axis = 0\n",
    "zipp3r.zipstep = 'x'\n",
    "zipp3r._axis = 2\n",
    "\n",
    "zipp3r.set_blockmap(axislabels='zyx')\n",
    "\n",
    "seam_idx = 0\n",
    "seam_pairs = zipp3r.get_seam_pairs(seam_idx)\n",
    "pairs = {i: pair for i, pair in enumerate(seam_pairs)}\n",
    "pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [zipp3r._blocks[idx] for idx in [8, 9]]\n",
    "segs, segs_ds, masks, masks_ds, mask = zipp3r.get_resegmentation_mask(blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the margin of the labelimage/zipmask blocks\n",
    "segm_imgs, segm_dsets = zipp3r.read_images(blocks, zipp3r.ods_labels, 'Label')\n",
    "mask_imgs, mask_dsets = zipp3r.read_images(blocks, zipp3r.ods_zipmask, 'Mask')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r._blocks[9].datasets['segm/labels_zip'].slices_blockfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mn = zipp3r.margin * zipp3r.n\n",
    "zipsels = zipp3r._get_zipsels(2)\n",
    "zipsels\n",
    "\n",
    "masks_ds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_slicer\n",
    "slcs = [slice(None)] * 3\n",
    "slc = {True: slice(None, mn), False: slice(-mn, -mn+1)}\n",
    "\n",
    "slcs[2] = slc[0]\n",
    "masks_ds[tuple(slcs)].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [0,1,2,3,4,5]\n",
    "t[slice(-1, None)]\n",
    "t[slice(None, 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for al, upper in zipsel.items():\n",
    "    if upper:\n",
    "        slices[al] = slice(slices[al].stop - mn, slices[al].stop)\n",
    "    else:\n",
    "        slices[al] = slice(slices[al].start, slices[al].start + mn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the labels that are on the seam\n",
    "# TODO: keep seam-labelset for next iteration\n",
    "labelsets = zipp3r.get_labels(segm_dsets)\n",
    "# check if there any labels in the combined set\n",
    "if not set().union(*labelsets):\n",
    "    pass\n",
    "else:\n",
    "    labelsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_imgs[1].path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create boolean forward maps\n",
    "fw_maps = tuple([True if l in labelset else False for l in range(0, seg.maxlabel + 1)] for labelset, seg in zip(labelsets, segm_imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# create the resegmentation mask\n",
    "rseg_dsets = tuple(np.array(fw_map)[segm_dset] for fw_map, segm_dset in zip(fw_maps, segm_dsets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# concatenate the margins of the block set\n",
    "segm_dset = self.concat_images(segm_dsets, self._axis)\n",
    "mask_dset = self.concat_images(mask_dsets, self._axis)\n",
    "rseg_dset = self.concat_images(rseg_dsets, self._axis)\n",
    "\n",
    "return segm_imgs, segm_dset, mask_imgs, mask_dset, rseg_dset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairs = {0: [16, 24], 1: [23, 31]}\n",
    "#pairs = {0: [16, 24], 1: [17, 25]}\n",
    "\n",
    "#images = ['nucl/prep']\n",
    "#labels = [zipp3r.ods_labels, zipp3r.ods_zipmask]\n",
    "#images = None\n",
    "#labels = [zipp3r.ods_zipmask]\n",
    "images = ['nucl/prep']\n",
    "labels = None\n",
    "settings = {'clim': {'nucl/prep': [0, 30000]}}\n",
    "zipp3r.view(pairs, images, labels, settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "block_ds._margins(fc, fC, fullsize, blocksize=176, margin=64, shift_final_block_inward=False)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "slices:                     with margin into the full dataset\n",
    "slices_region:              without margin into the full dataset\n",
    "slices_blockfile:           with margin into the block\n",
    "slices_region_blockfile:    without margin into the block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slices of margins into full dataset\n",
    "\n",
    "axlab = 'zyx'\n",
    "m = 64\n",
    "n = 2\n",
    "mn = m * n\n",
    "zipstep = 'x'\n",
    "\n",
    "idx = 9\n",
    "# upper \n",
    "block = zipp3r._blocks[idx]\n",
    "bslices = block.slices_region\n",
    "slices = {al: slc for al, slc in bslices.items() if al in axlab}\n",
    "slices[zipstep] = slice(slices[zipstep].stop - mn, slices[zipstep].stop)\n",
    "slices\n",
    "\n",
    "offsets = {al: slc.start for al, slc in bslices.items() if al in axlab}\n",
    "offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(block, al, full_coord):\n",
    "    offset = block.slices_region[al].start - block.slices_region_blockfile[al].start\n",
    "    block_coord = full_coord - offset\n",
    "    return block_coord\n",
    "\n",
    "idx = 9\n",
    "block = zipp3r._blocks[idx]\n",
    "foo(block, 'y', 176)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block.slices[al].start, block.slices_blockfile[al].start\n",
    "block.slices_region[al].start, block.slices_region_blockfile[al].start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = 'x'\n",
    "block._margins(\n",
    "    fc=slices[al].start,\n",
    "    fC=slices[al].stop,\n",
    "    fullsize=zipp3r.fullsize[al],\n",
    "    blocksize=zipp3r.blocksize[al],\n",
    "    margin=zipp3r.blockmargin[al],\n",
    "    shift_final_block_inward=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower\n",
    "idx = 12\n",
    "block = zipp3r._blocks[idx]\n",
    "bslices = block.slices_region\n",
    "slices = {al: slc for al, slc in bslices.items() if al in axlab}\n",
    "slices[zipstep] = slice(slices[zipstep].start, slices[zipstep].start + mn)\n",
    "slices\n",
    "\n",
    "offsets = {al: slc.start for al, slc in bslices.items() if al in axlab}\n",
    "offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo(block, slices[al].start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block.slices[al].start, block.slices_blockfile[al].start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = 'x'\n",
    "block._margins(\n",
    "    slices[al].start, slices[al].stop,\n",
    "    fullsize=zipp3r.fullsize[al],\n",
    "    blocksize=zipp3r.blocksize[al],\n",
    "    margin=zipp3r.blockmargin[al],\n",
    "    shift_final_block_inward=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.fullsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block0 = zipp3r._blocks[0]\n",
    "block = zipp3r._blocks[idx]\n",
    "ids = 'segm/labels_zip'\n",
    "\n",
    "block.create_dataset(ids, axlab=axlab, slices=slices)\n",
    "block_ds = block.datasets[ids]\n",
    "\n",
    "for al in 'zyx':\n",
    "    slc = slice(\n",
    "        block_ds.slices[al].start - offsets[al],\n",
    "        block_ds.slices[al].stop - offsets[al],\n",
    "    )\n",
    "    block_ds.slices_blockfile[al] = slc\n",
    "\n",
    "# block.slices, block.slices_region, block.slices_blockfile, block.slices_region_blockfile\n",
    "# block_ds.slices, block_ds.slices_blockfile\n",
    "#block_ds.slices_region, block_ds.slices_region_blockfile\n",
    "# block_ds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ds.dtype = 'int'\n",
    "block_ds.create_image()\n",
    "block_ds.read(from_block=True, padded=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "spacing = [block_ds.elsize[al] for al in block_ds.axlab if al in 'xyz']\n",
    "starts = [slc.start for al, slc in block.slices.items() if al in 'xyz']\n",
    "origin = [sp * st for sp, st in zip(spacing, starts)]\n",
    "spacing = spacing or [1, 1, 1]\n",
    "origin = origin or [0, 0, 0]\n",
    "from stapl3d.preprocessing.registration import get_affine\n",
    "affine = get_affine([0, 0, 0], spacing, origin)\n",
    "affine = np.copy(affine)\n",
    "print(affine, affine2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "240*elsize[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine3 = np.array(affine)\n",
    "affine3[2,3] = 0\n",
    "affine2 = np.array(affine)\n",
    "affine2[2,3] = affine[2,3] + 79.7050568181818\n",
    "viewer = napari.Viewer()\n",
    "elsize = [block_ds.elsize[al] for al in 'zyx']\n",
    "viewer.add_labels(block_ds.image.ds, name='foo', affine=affine)\n",
    "viewer.add_labels(block_ds.image.ds, name='foo', affine=affine2)\n",
    "viewer.add_labels(block_ds.image.ds, name='foo', affine=affine3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ds.image.ds.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "24*0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'{block.id}_{ids}'\n",
    "data = block_ds.image.ds\n",
    "elsize = [block_ds.elsize[al] for al in block_ds.axlab]\n",
    "name, data.shape, elsize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ds.image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#zipp3r.zipsteps = 'zy'\n",
    "#zipp3r.seams = [0]\n",
    "\n",
    "#zipp3r.estimate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.margin = 64\n",
    "zipp3r.n = 2\n",
    "zipp3r.zipstep = 'x'\n",
    "zipp3r._axis = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zipp3r._set_additional_block_slices(zipp3r._blocks[:2], include_margin=True)\n",
    "zipp3r._blocks[0].slices_region_blockfile, zipp3r._blocks[0].slices_margin_blockfile\n",
    "zipp3r._blocks[1].slices_region_blockfile, zipp3r._blocks[1].slices_margin_blockfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.ods_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_ds.slices_margin_blockfile = {al: slc for al, slc in block.slices_margin_blockfile.items() if al in axlab}\n",
    "block_ds.slices_margin_blockfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block0 = zipp3r._blocks[block_idxs[0]]\n",
    "\n",
    "for block_idx in block_idxs:\n",
    "\n",
    "    block = self._blocks[block_idx]\n",
    "\n",
    "    for ids in images + labels:\n",
    "\n",
    "        block.create_dataset(ids)\n",
    "        block_ds = block.datasets[ids]\n",
    "        block_ds.read(from_block=True, read_margin=True)  # TODO: read only slices_blockfile_margins\n",
    "        elsize = [block_ds.elsize[al] for al in block_ds.axlab]\n",
    "\n",
    "        name = f'{block.id}_{ids}'\n",
    "        data = block_ds.image.ds\n",
    "\n",
    "        spacing = [block_ds.elsize[al] for al in block_ds.axlab if al in 'xyz']\n",
    "        starts = [slc.start for al, slc in block.slices.items() if al in 'xyz']\n",
    "        origin = [sp * st for sp, st in zip(spacing, starts)]\n",
    "        spacing = spacing or [1, 1, 1]\n",
    "        origin = origin or [0, 0, 0]\n",
    "        from stapl3d.preprocessing.registration import get_affine\n",
    "        affine = get_affine([0, 0, 0], spacing, origin)\n",
    "        affine = np.copy(affine)\n",
    "\n",
    "        if ids in images:\n",
    "            self.viewer.add_image(data, name=name, scale=elsize, affine=affine)\n",
    "            clim = self.viewer.layers[f'{block0.id}_{ids}'].contrast_limits\n",
    "            self.viewer.layers[f'{block.id}_{ids}'].contrast_limits = clim\n",
    "        else:\n",
    "            self.viewer.add_labels(data, name=name, scale=elsize, affine=affine)\n",
    "\n",
    "axlab = block_ds.axlab\n",
    "\n",
    "self.viewer.dims.axis_labels = [al for al in axlab]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.zipstep = 'x'\n",
    "zipp3r._axis = 2\n",
    "zipp3r.margin = 64\n",
    "zipp3r.maxlabel = 1000000\n",
    "pair = [0, 1]\n",
    "zipp3r.j = 0\n",
    "blocks = [zipp3r._blocks[idx] for idx in pair]\n",
    "n_max = zipp3r._get_nmax(blocks, zipp3r._axis, zipp3r.margin)  # TODO: n_max as ndim\n",
    "print(n_max)\n",
    "\n",
    "#zipp3r.process_pair(0, blocks, n_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.zipstep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.n = min(n_max, 3)  # number of blockmargins\n",
    "\n",
    "segm_imgs, segm_dsets = zipp3r.read_images(blocks, zipp3r.ods_labels, 'Label')\n",
    "mask_imgs, mask_dsets = zipp3r.read_images(blocks, zipp3r.ods_zipmask, 'Mask')\n",
    "labelsets = zipp3r.get_labels(segm_dsets)\n",
    "\n",
    "\n",
    "# create boolean forward maps\n",
    "fw_maps = tuple([True if l in labelset else False for l in range(0, seg.maxlabel + 1)] for labelset, seg in zip(labelsets, segm_imgs))\n",
    "# create the resegmentation mask\n",
    "rseg_dsets = tuple(np.array(fw_map)[segm_dset] for fw_map, segm_dset in zip(fw_maps, segm_dsets))\n",
    "\n",
    "# concatenate the margins of the block set\n",
    "segm_dset = zipp3r.concat_images(segm_dsets, zipp3r._axis)\n",
    "mask_dset = zipp3r.concat_images(mask_dsets, zipp3r._axis)\n",
    "rseg_dset = zipp3r.concat_images(rseg_dsets, zipp3r._axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(segm_dsets[0]), np.sum(segm_dsets[1])\n",
    "np.sum(fw_maps[0]), np.sum(fw_maps[1])\n",
    "np.sum(rseg_dsets[0]), np.sum(rseg_dsets[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks[1].slices, blocks[1].slices_blockfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = [es for al, es in elsize.items() if al in 'xyz']\n",
    "starts = [slc.start for al, slc in self.slices.items() if al in 'xyz']\n",
    "origin = [sp * st for sp, st in zip(spacing, starts)]\n",
    "spacing = spacing or [1, 1, 1]\n",
    "origin = origin or [0, 0, 0]\n",
    "self.affine = get_affine([0, 0, 0], spacing, origin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.view_pair()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_labels(segm_dsets[0])\n",
    "viewer.add_labels(segm_dsets[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fw_maps[1]\n",
    "np.unique(segm_dsets[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_imgs[0].maxlabel, segm_imgs[1].maxlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fw_maps[1]), np.max(segm_dsets[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs, segs_ds, masks, masks_ds, mask = zipp3r.get_resegmentation_mask(blocks)\n",
    "np.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sum(rseg_dset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axlab = 'zyx'  # FIXME: assuming zyx order\n",
    "zipp3r.set_blockmap(axislabels=axlab)\n",
    "zipp3r.blockmap\n",
    "zipp3r.zipstep = 'y'\n",
    "zipp3r._axis = zipp3r.zipsteps.index(zipp3r.zipstep)\n",
    "seam_idx = 0\n",
    "seam_pairs = zipp3r.get_seam_pairs(seam_idx)\n",
    "seam_pairs\n",
    "list(seam_pairs[seam_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "zipp3r.zipsteps = 'x'\n",
    "zipp3r.seams = [0]\n",
    "\n",
    "\"\"\"\n",
    "zipp3r.zipstep = 'y'\n",
    "zipp3r._axis = zipp3r.zipsteps.index(zipp3r.zipstep)\n",
    "\n",
    "\n",
    "offsets = [0, 1]\n",
    "seamgrid_shape = np.maximum(np.array(zipp3r.blockmap.shape) - 1, np.array([1, 1, 1]))\n",
    "\n",
    "for offset in offsets:\n",
    "\n",
    "    zipp3r._seams = []\n",
    "    for seam_idx in range(offset, seamgrid_shape[zipp3r._axis], 2):\n",
    "        zipp3r._seams.append(seam_idx)\n",
    "\n",
    "zipp3r._seams\n",
    "\"\"\"\n",
    "\n",
    "zipp3r.estimate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seamgrid_shape\n",
    "zipp3r._axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['nucl/prep', 'memb/prep']\n",
    "labels = ['segm/labels', 'segm/labels_zip', 'segm/labels_zipmask']\n",
    "zipp3r.view(list(seam_pairs[0]), images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "self = zipp3r\n",
    "seam_idx = 0\n",
    "#zipp3r.get_seam_pairs(0)\n",
    "seamgrid_shape = np.maximum(np.array(self.blockmap.shape) - 1, np.array([1, 1, 1]))\n",
    "seamnumbers = np.unravel_index(seam_idx, seamgrid_shape)\n",
    "seamnumbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the blockmap to get the block indices of the blocks around the seam.\n",
    "if self.zipstep == 'q':\n",
    "    slcs = [slice(seamnumbers[d], seamnumbers[d] + 2) for d in range(3)]\n",
    "    sh = (1, 4)  # single quad as list of len 4?\n",
    "else:\n",
    "    axis = 'zyx'.index(self.zipstep)  # FIXME: assuming zyx order\n",
    "    slcs = [slice(None) for d in range(3)]\n",
    "    slcs[axis] = slice(seamnumbers[0], seamnumbers[0] + 2)\n",
    "    sh = (-1, 2)  # list of pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = np.squeeze(self.blockmap[tuple(slcs)])\n",
    "# FIXME: assumes zyx order\n",
    "#newaxes = {'x': [0, 1, 2], 'y': [2, 0, 1], 'z': [2, 1, 0], 'q': [0, 1, 2]}\n",
    "#pairs = np.moveaxis(pairs, [0, 1, 2], newaxes)\n",
    "axis = self._axis if self.zipstep in 'zyx' else 0\n",
    "pairs = np.moveaxis(pairs, [0, 1, 2], [2, 1, 0])\n",
    "pairs = np.reshape(pairs, sh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax: operate over these axes, # tp: transpose axes, # sh: reshape\n",
    "tps = {'x': [0, 1], 'y': [1, 0], 'z': []}  # TODO: determine tp_z\n",
    "\n",
    "# Slice the blockmap to get the block indices of the blocks around the seam.\n",
    "if self.zipstep == 'q':\n",
    "    slcs = [slice(seamnumbers[d], seamnumbers[d] + 2) for d in range(3)]\n",
    "    tp = [0, 1]\n",
    "    sh = (1, 4)  # single quad as list of len 4?\n",
    "else:\n",
    "    axis = 'zyx'.index(self.zipstep)  # FIXME: assuming zyx order\n",
    "    slcs = [slice(None) for d in range(3)]\n",
    "    slcs[axis] = slice(seamnumbers[0], seamnumbers[0] + 2)\n",
    "    tp = tps[self.zipstep]\n",
    "    sh = (-1, 2)  # list of pairs\n",
    "\n",
    "pairs = np.squeeze(self.blockmap[tuple(slcs)])\n",
    "pairs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll axis until it is at the back\n",
    "\n",
    "pairs.shape\n",
    "#np.transpose(pairs, [2, 1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(np.moveaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = np.reshape(, sh)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zipp3r.maxlabel = zipp3r._prep_paths(zipp3r.outputpaths['estimate'])['maxlabelfile']\n",
    "zipp3r.prep_maxlabel('', 'segm/labels_zip', seamnumber=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have specified the shape of the processing blocks in the parameter file. Usually we would opt for a blocksize of ~100-200 million voxels; now we chose a blocksize in xy of 176 for 64 blocks of ~6M voxels. We keep the margin similar to what we set for big datasets as reducing it may hinder adequate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['blocks']['blockinfo'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full anatomy of the blocked processing can now be loaded through the blocker object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d import blocks\n",
    "block3r = blocks.Block3r(image_in, parameter_file, prefix=dataset)\n",
    "print(block3r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In initializing the *block3r* object, the sizes for the zyxct-dimensions were read from the input data and the dimensions that were specified in the configuration file for blocksize were substituted to determine the 5D-blocksize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For segmentation, we use a weighted sum of the membrane channels (ch3, ch5, ch6, ch7). The weights [0.5, 0.5, 1.0, 1.0] work well for this data. We set the name and internal .h5 path to 'memb/mean'.\n",
    "We have specified this in the parameter file HFK16w.yml:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['splitter']['split']['volumes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above indicates that, in addition to the membrane sum, we generate a mean over all channels (used for generating masks). Importantly, we specify that we want to output channel 0 (DAPI), because we will use it to create a nuclear mask. \n",
    "\n",
    "Now we are ready to call the function that computes the membrane mean, and splits the data into blocks at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitt3r = blocks.Splitt3r(image_in, parameter_file, prefix=dataset)\n",
    "splitt3r.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datablocks are written to the *HFK16w/blocks/* directory and are postfixed by the numeric ID of the block HFK16w/blocks/HFK16w_**B{b:05}**.h5.\n",
    "\n",
    "These are some of the files that were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "filelist = glob(os.path.join(os.path.abspath('.'), 'blocks', f'{dataset}_*.h5'))\n",
    "filelist.sort()\n",
    "\n",
    "f'Number of blocks: {len(filelist)}'\n",
    "filelist[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting hdf5 files have three datasets named according to 'outputvolumes' entries in the cfg['splitter']['split'] specification, i.e. they have the following internal file structure:\n",
    "- <...>.h5/mean\n",
    "- <...>.h5/chan/ch00\n",
    "- <...>.h5/memb/mean\n",
    "\n",
    "It can be inspected and listed with the help of h5py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def extract_node_names(name, node):\n",
    "    if isinstance(node, h5py.Dataset):\n",
    "        nodes.append(name)\n",
    "    return None\n",
    "\n",
    "nodes = []\n",
    "with h5py.File(filelist[0], 'r') as f:\n",
    "    f.visititems(extract_node_names)\n",
    "    pprint({'dataset names': nodes})\n",
    "    idx = 0\n",
    "    print(f'dataset {nodes[idx]} properties: ', f[nodes[idx]])\n",
    "    print(f'dataset {nodes[idx]} resolution: ', f[nodes[idx]].attrs['element_size_um'])\n",
    "    print(f'dataset {nodes[idx]} axes labels: ', f[nodes[idx]].attrs['DIMENSION_LABELS'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, we also need to visually inspect the resulting averaged volumes. We can use the napari viewer method provided in the *splitt3r* object. We limit to the first 42 blocks and pick the mean membrane channel for demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(42))  # block indices\n",
    "images = ['memb/mean']\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D splitt3r demo',\n",
    "    'crosshairs': [int(splitt3r.fullsize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clim': [0, 5000],\n",
    "}\n",
    "\n",
    "splitt3r.view(input=idxs, images=images, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a grip on how the dataset is layed out in blocks, we can alternate the colormaps of the blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate colormaps.\n",
    "cmaps = ['cyan', 'magenta', 'yellow']\n",
    "for i, lay in enumerate(splitt3r.viewer.layers):\n",
    "    lay.colormap = cmaps[i % len(cmaps)]\n",
    "lay.colormap = 'gray'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membrane enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before segmentation, we perform membrane enhancement.\n",
    "\n",
    "For the demo we do not want to be dependent on the third-party [ACME](https://wiki.med.harvard.edu/SysBio/Megason/ACME) software and provide the output that otherwise results from the ACME procedure. We split it into blocks, and write it as separate datasets in the same files as the channel data.\n",
    "\n",
    "Alternatively, if you have ACME installed and want to run it, set an `ACME` path environment variable or point `ACMEdir` to the directory with the binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims_filepath = f'{dataset}_shading_stitching.ims'  # f'{dataset}_shading_stitching_biasfield.ims'\n",
    "image_in = ims_filepath\n",
    "\n",
    "max_workers = 5  # NB: ACME is memory-intensive\n",
    "\n",
    "from stapl3d.segmentation import enhance\n",
    "enhanc3r = enhance.Enhanc3r(image_in, parameter_file, prefix=dataset, max_workers=max_workers)\n",
    "enhanc3r.ACMEdir = os.environ.get('ACME')\n",
    "\n",
    "if enhanc3r.ACMEdir:\n",
    "\n",
    "    # Perform membrane enhancement.\n",
    "    enhanc3r.run()\n",
    "\n",
    "else:\n",
    "\n",
    "    acme_filepath = f'{dataset}_shading_stitching_ACME.h5'\n",
    "\n",
    "    # Download precomputed membrane enhancement.\n",
    "    if not os.path.exists(acme_filepath):\n",
    "        url = 'https://surfdrive.surf.nl/files/index.php/s/oQcxIocFBkaXwJe/download'\n",
    "        urllib.request.urlretrieve(url, acme_filepath)\n",
    "\n",
    "    # Split into blocks\n",
    "    from stapl3d import blocks\n",
    "    for ids in ['memb/preprocess', 'memb/planarity']:\n",
    "        filepath_in = f'{acme_filepath}/{ids}'\n",
    "        splitt3r = blocks.Splitt3r(filepath_in, parameter_file, prefix=dataset)\n",
    "        splitt3r.volumes = {ids: {'output_ND': True}}  # override volumes from parameter file\n",
    "        splitt3r.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vizualize the membrane-enhanced volume with napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize viewer.\n",
    "idxs = list(range(42))  # block indices\n",
    "images = ['memb/planarity']\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D enhanc3r demo',\n",
    "    'crosshairs': [int(enhanc3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clim': [0, 0.05],\n",
    "}\n",
    "\n",
    "enhanc3r.view(input=idxs, images=images, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The segmentation is parallelized over the blocks we just created. Each of the 64 files is processed seperately.\n",
    "The segmentation routine is associated with a fair amount of steps and parameters. This list all the parameters specified in the yml-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['segmentation']['estimate'])  # TODO: need to preserve order of print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blocks will processed in order according to the steps defined in the parameter file. Operations are listed below and step names have to be prefixed with these keywords.\n",
    "- *prep*: filtering of volumes\n",
    "- *mask*: compartment mask creation\n",
    "- *combine*: mask combination\n",
    "- *seed*: seed generation\n",
    "- *segment*: watershed segmentation\n",
    "- *filter*: size filtering and label masking\n",
    "\n",
    "For your own data, it is advised to start with tuning the following parameters to optimize segmentation:\n",
    "- mask_memb : threshold\n",
    "- mask_nucl : sauvola : window_size\n",
    "- mask_nucl : sauvola : threshold\n",
    "- mask_nucl : sauvola : absmin\n",
    "- seeds : peaks : window\n",
    "- seeds : peaks : window\n",
    "- segment : watershed : compactness\n",
    "- prep_memb : filter : sigma\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we calculate the segments for each block. Segmentation time of single block is in the minutes-range. The 106 x 240 x 240 blocksize (including the margin) will take ~1GB of memory per process. Please set the number of processes so that you will stay within RAM. `max_workers = 8` would be a fairly safe bet for modern systems; `max_workers = 0` results in using all available processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.segmentation import segment\n",
    "\n",
    "max_workers = 0\n",
    "\n",
    "segment3r = segment.Segment3r(image_in, parameter_file, prefix=dataset, max_workers=max_workers)\n",
    "segment3r.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report pages (pdf) have been written to the *HFK16w/blocks/* directory. Let's look at one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 1\n",
    "# Get the outputpaths of the 'estimate' method for a block.\n",
    "_, opaths = segment3r.fill_paths('estimate', reps={'b': block_idx})\n",
    "# (Re)generate the report from the data and plot inline.\n",
    "segment3r.report(outputpath=None, ioff=False, outputs=opaths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From top to bottom, images are show for:\n",
    " - the smoothed DAPI and mean membrane channels\n",
    " - the nuclear mask and the membrane mask\n",
    " - the combined mask with detected peaks and overlaid on the distance transform image\n",
    " - the first and the final watershed results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the 'labels' argument to visualize masks and labels in napari. First, this overlays the membrane mask with the planarity volume for the top row of blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(8))  # block indices\n",
    "images = ['memb/planarity']\n",
    "labels = ['nucl/mask']\n",
    "\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D segment3r demo',\n",
    "    'crosshairs': [int(segment3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clim': {'memb/planarity': [0, 0.05]},\n",
    "    'opacity': {'nucl/mask': 0.5},\n",
    "}\n",
    "\n",
    "segment3r.view(input=idxs, images=images, labels=labels, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at the extracted segments for the block we view as a pdf report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['nucl/prep']\n",
    "labels = ['segm/labels']\n",
    "\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D segment3r demo',\n",
    "    'crosshairs': [int(segment3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clim': {'nucl/prep': [0, 20000]},\n",
    "    'opacity': {'segm/labels': 0.8},\n",
    "}\n",
    "\n",
    "segment3r.view(input=block_idx, images=images, labels=labels, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having parallelized the segmentation process for increased analysis speed and reduced memory footprint, the need arises to reassemble the blocks into a final combined segmentation volume without seams at the block boundaries. These seams are a consequence of trivial parallelization in processing the individual blocks (i.e. without communication between the processes). They manifest through partial cells lying on the block boundaries that have been assigned different labels in different blocks. Importantly, these doubly segmented cells may not perfectly match up over the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be demonstrated by loading the segmentation of the top two rows of blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment3r.view(input=list(range(16)), images=images, labels=labels, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These block-boundary-segments need to be resegmented in order to complete the accurate segmentation of the full dataset. We refer to this correct reassembly of the datablocks as zipping. In short, it consists of identifying the segments lying on the boundaries, removing them, and resegmenting that space. We aimed to design the procedure such that it requires minimal computational resources and expertise (fast, with a low memory footprint, and without the need for communication between processes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a one-liner for computing all the steps in the zip:\n",
    "```\n",
    "zipp3r.run()\n",
    "```\n",
    "which combines these two steps:\n",
    "```\n",
    "zipp3r.relabel()\n",
    "zipp3r.estimate()\n",
    "```\n",
    "\n",
    "For this demo, we will be much more verbose to illustrate the zipping process. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a convenience function that merges datablocks into a single volume and returns a single z-plane for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def slice_dset(filepath, slc=20):\n",
    "    \"\"\"Return sliced data.\"\"\"\n",
    "\n",
    "    im = Image(filepath)\n",
    "    im.load()\n",
    "    im.slices[im.axlab.index('z')] = slice(slc, slc + 1, 1)\n",
    "    data = im.slice_dataset()\n",
    "    im.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "def merge_and_slice_dset(merg3r, ids, slc=20):\n",
    "    \"\"\"Merge volume and return sliced data.\"\"\"\n",
    "\n",
    "    # Run the block merge.\n",
    "    merg3r.vols = [list(merg3r.volumes.keys()).index(ids)]  # select volume by index\n",
    "    merg3r.run()\n",
    "\n",
    "    # Get a slice of the merged data.\n",
    "    opaths = merg3r.outputpaths['merge']\n",
    "    reps = {'a': ids, 'A': ids.replace('/', '-')}  # insert volume name for a/A\n",
    "    opaths = merg3r._prep_paths(opaths, reps=reps)\n",
    "    data = slice_dset(opaths['volume'], slc)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting labels, we define a label shuffling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from random import shuffle\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "def shuffle_labels(labels):\n",
    "    \"\"\"Shuffle labels in a volume.\"\"\"\n",
    "\n",
    "    labels = relabel_sequential(labels)[0]\n",
    "    ulabels = np.unique(labels[:])[1:]\n",
    "    relabeled = [l for l in range(0, len(ulabels))]\n",
    "    shuffle(relabeled)\n",
    "    labels = np.array([0] + relabeled)[labels]\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merger object is prepped for merging 4 output volumes defined in the parameter file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d import blocks\n",
    "merg3r = blocks.Merg3r(image_in, parameter_file, prefix=dataset)\n",
    "merg3r.volumes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check with the membrane mean blocks. This should output an image of 1408 x 1408."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = merge_and_slice_dset(merg3r, ids='memb/mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img, cmap='gray', vmax=5000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, we can show the labels with the seams before zipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = shuffle_labels(merge_and_slice_dset(merg3r, ids='segm/labels'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(label2rgb(labels))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the zipp3r.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.segmentation import zipping\n",
    "#from importlib import reload\n",
    "#reload(zipping)\n",
    "zipp3r = zipping.Zipp3r(image_in, parameter_file, prefix=dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first perform a sequential relabeling of all the blocks to make each label unique and save it to a new dataset 'segm/labels_zip'. Also a volume 'segm/labels_zipmask' is created to track the area that is resegmented.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp3r.relabel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set up the zipping estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# write maxlabels to file\n",
    "arglist = zipp3r._prep_step('estimate')\n",
    "np.array(zipp3r._gather_maxlabels(zipp3r.ods_labels))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zipp3r.fullsize\n",
    "#zipp3r.estimate()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zipp3r.set_blockmap()\n",
    "zipp3r._resegment_block_boundaries(axis=0, seamnumbers=[0,0,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the zipping procedure, we employ an order such that no blocks are handled concurrently. First, blocks with overlap in the Y-dimension are processed (odd and even zip-lines separately); then X-ziplines; then the corners where four datablocks overlap are resegmented. For demo purpose, we keep track of the output for each step and store it in `imgs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "\n",
    "# ziplines\n",
    "for axis in [1, 2]:\n",
    "    for offset in [0, 1]:\n",
    "        n_seams = zipp3r._seamgrid.shape[axis - 1]\n",
    "        zipp3r.compute_zip_step(\n",
    "            axis=axis,\n",
    "            starts=[offset, 0],\n",
    "            stops=[n_seams, 1],\n",
    "            steps=[2, 2],\n",
    "            )\n",
    "        _ = zipp3r._gather_maxlabels(zipp3r.ods_labels)\n",
    "        imgs.append(merge_and_slice_dset(merg3r, 'segm/labels_zip'))\n",
    "\n",
    "# zipquads\n",
    "for start_y in [0, 1]:\n",
    "    for start_x in [0, 1]:\n",
    "        zipp3r.compute_zip_step(\n",
    "            axis=0,\n",
    "            starts=[start_y, start_x],\n",
    "            stops=zipp3r._seamgrid.shape,\n",
    "            steps=[2, 2],\n",
    "            )\n",
    "        _ = zipp3r._gather_maxlabels(zipp3r.ods_labels)\n",
    "        imgs.append(merge_and_slice_dset(merg3r, 'segm/labels_zip'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 4, figsize=(24, 12))\n",
    "for img, ax in zip(imgs, axs.flat):\n",
    "    ax.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newly processed zip-lines are assigned high labels indicated in yellow of the viridis colormap, nicely demonstrating the zipping process.\n",
    "\n",
    "<!---The zip-lines still have seams in the places where they intersect. Next we process zip-quads, in which the segments on these intersections are resegmented to finish the zip.-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compare the labels before and after the zip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_zipped = shuffle_labels(merge_and_slice_dset(merg3r, ids='segm/labels_zip'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 2, figsize=(16, 32))\n",
    "for img, ax in zip([labels, labels_zipped], axs.flat):\n",
    "    ax.imshow(label2rgb(shuffle_labels(img)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the zip result with napari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idss = ['segm/labels', 'segm/labels_zip']\n",
    "\n",
    "merg3r = blocks.Merg3r(image_in, parameter_file, prefix=dataset)\n",
    "merg3r.vols = [list(merg3r.volumes.keys()).index(ids) for ids in idss]\n",
    "merg3r.run()\n",
    "\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D merg3r demo',\n",
    "    'crosshairs': [int(merg3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clims': [0, 1],\n",
    "    'opacity': 1,\n",
    "}\n",
    "\n",
    "filepath = merg3r.outputpaths['postprocess']['aggregate']\n",
    "merg3r.view(input=filepath, images=[], labels=idss, settings=viewer_settings)\n",
    "\n",
    "# NOTE: some new seams are created on the margins because the blocks of this demo are too small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compartmental segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In STAPL-3D, we use rich multidimensional data to obtain a robust segmentation. We can also use the information we have to perform subcellular segmentation. Here, we split segments in nucleus and membrane subsegments such that we can specifically extract intensities from the appropriate voxels for the type of staining (nuclear or membranal). In addition, the subsegmentation opens up possibilities for defining compound features that inform on internal cell structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.segmentation import segment\n",
    "\n",
    "subsegment3r = segment.Subsegment3r(image_in, parameter_file, prefix=dataset)\n",
    "subsegment3r.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols = [f'segm/labels_{vol}' for vol in ['full', 'nucl', 'memb']]\n",
    "merg3r = blocks.Merg3r(image_in, parameter_file, prefix=dataset)\n",
    "merg3r.volumes = {vol: {'format': 'h5', 'suffix': None, 'is_labelimage': True} for vol in vols}\n",
    "merg3r._init_paths_merger()\n",
    "merg3r.run()\n",
    "\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D merg3r demo',\n",
    "    'crosshairs': [int(merg3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clims': [0, 1],\n",
    "    'opacity': 1,\n",
    "}\n",
    "\n",
    "filepath = merg3r.outputpaths['postprocess']['aggregate']\n",
    "merg3r.view(input=filepath, images=[], labels=vols, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stapl3d",
   "language": "python",
   "name": "stapl3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:52) \n[Clang 13.0.1 ]"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
