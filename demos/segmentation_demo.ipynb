{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAPL-3D segmentation demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the core components of the STAPL-3D segmentation pipeline: **blockwise segmentation** and **zipping**.\n",
    "\n",
    "If you did not follow the STAPL-3D README: please find STAPL-3D and the installation instructions [here](https://github.com/RiosGroup/STAPL3D) before doing this demo.\n",
    "\n",
    "Because STAPL-3D is all about big datafiles, we provide small cutouts and precomputed summary data that will be downloaded while progressing through the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some general settings and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Imports.\n",
    "import os\n",
    "import yaml\n",
    "import urllib.request\n",
    "from pprint import pprint\n",
    "\n",
    "# Yaml printing function.\n",
    "def yprint(ydict):\n",
    "    \"\"\"Print dictionary in yaml formatting.\"\"\"\n",
    "    print(yaml.dump(ydict, default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define where you want the data to be downloaded by changing *projectdir*; default is the current demo directory. The name of the dataset is *'HFK16w'* (for Human Fetal Kidney - 16 weeks). We create a directory for the dataset and jump to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = '.'\n",
    "dataset = 'HFK16w'\n",
    "\n",
    "datadir = os.path.join(projectdir, dataset)\n",
    "\n",
    "os.makedirs(datadir, exist_ok=True)\n",
    "os.chdir(datadir)\n",
    "f'working in directory: {os.path.abspath(\".\")}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define STAPL3D parameters preferably using a [yaml](https://yaml.org) parameter file. It has a simple structure and can be parsed in Python and `bash`. We will download the example, read it into a dictionary structure, list all entries and show the entry that contains information on the default directory structure for STAPL3D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_file = f'{dataset}.yml'\n",
    "\n",
    "# Download the yml-file.\n",
    "if not os.path.exists(parameter_file):\n",
    "    url = 'https://surfdrive.surf.nl/files/index.php/s/Ubx9wVon5CIuIzo/download'\n",
    "    urllib.request.urlretrieve(url, parameter_file)\n",
    "\n",
    "# Load parameter file.\n",
    "with open(parameter_file, 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "# List all entries.\n",
    "cfg.keys()\n",
    "\n",
    "# Inspect directory tree.\n",
    "yml_entry = 'dirtree'\n",
    "yprint(cfg[yml_entry])  # in yaml format\n",
    "pprint(cfg[yml_entry])  # as a dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provided a preprocessed data cutout in the Imaris v5.5 file format. which is an hdf5 file with 5 dimensions (a free [Imaris Viewer](https://imaris.oxinst.com/imaris-viewer) is available; and the file format can be inspected with [HDFview](https://www.hdfgroup.org/downloads/hdfview/) or with `h5ls` or `h5py`.\n",
    "\n",
    "We download the file and name it according to the default STAPL-3D pipeline conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims_filepath = f'{dataset}_shading_stitching.ims'  # f'{dataset}_shading_stitching_biasfield.ims'\n",
    "\n",
    "# Download the ims-file.\n",
    "if not os.path.exists(ims_filepath):\n",
    "    url = 'https://surfdrive.surf.nl/files/index.php/s/NxWhUWuLQBHPMGV/download'\n",
    "    urllib.request.urlretrieve(url, ims_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the STAPL-3D Image class to load this file and inspect it's properties. We'll also save the dimensions, the Z-dimension and the number of channels in convenience variables `dims`, `Z` and `C`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print image properties.\n",
    "from stapl3d import Image\n",
    "image_in = ims_filepath\n",
    "im = Image(image_in)\n",
    "im.load(load_data=False)\n",
    "props = im.get_props()\n",
    "im.close()\n",
    "pprint(props)\n",
    "\n",
    "# Convinience variables.\n",
    "dims = im.dims\n",
    "Z = im.dims[im.axlab.index('z')]\n",
    "C = im.dims[im.axlab.index('c')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In processing the full dataset, this cutout of **106 x 1408 x 1408 x 8** would equate to a single datablock, but for this demo we will further subdivide this block to demonstrate the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have specified the shape of the processing blocks in the parameter file. Usually we would opt for a blocksize of ~100-200 million voxels; now we chose a blocksize in xy of 176 for 64 blocks of ~6M voxels. We keep the margin similar to what we set for big datasets as reducing it may hinder adequate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['blocks']['blockinfo'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full anatomy of the blocked processing can now be loaded through the blocker object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d import blocks\n",
    "block3r = blocks.Block3r(image_in, parameter_file, prefix=dataset)\n",
    "print(block3r)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In initializing the *block3r* object, the sizes for the zyxct-dimensions were read from the input data and the dimensions that were specified in the configuration file for blocksize were substituted to determine the 5D-blocksize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For segmentation, we use a weighted sum of the membrane channels (ch3, ch5, ch6, ch7). The weights [0.5, 0.5, 1.0, 1.0] work well for this data. We set the name and internal .h5 path to 'memb/mean'.\n",
    "We have specified this in the parameter file HFK16w.yml:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['splitter']['split']['volumes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above indicates that, in addition to the membrane sum, we generate a mean over all channels (used for generating masks). Importantly, we specify that we want to output channel 0 (DAPI), because we will use it to create a nuclear mask. \n",
    "\n",
    "Now we are ready to call the function that computes the membrane mean, and splits the data into blocks at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitt3r = blocks.Splitt3r(image_in, parameter_file, prefix=dataset)\n",
    "splitt3r.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datablocks are written to the *HFK16w/blocks/* directory and are postfixed by the numeric ID of the block HFK16w/blocks/HFK16w_**B{b:05}**.h5.\n",
    "\n",
    "These are some of the files that were generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "filelist = glob(os.path.join(os.path.abspath('.'), 'blocks', f'{dataset}_*.h5'))\n",
    "filelist.sort()\n",
    "\n",
    "f'Number of blocks: {len(filelist)}'\n",
    "filelist[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting hdf5 files have three datasets named according to 'outputvolumes' entries in the cfg['splitter']['split'] specification, i.e. they have the following internal file structure:\n",
    "- <...>.h5/mean\n",
    "- <...>.h5/chan/ch00\n",
    "- <...>.h5/memb/mean\n",
    "\n",
    "It can be inspected and listed with the help of h5py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def extract_node_names(name, node):\n",
    "    if isinstance(node, h5py.Dataset):\n",
    "        nodes.append(name)\n",
    "    return None\n",
    "\n",
    "nodes = []\n",
    "with h5py.File(filelist[0], 'r') as f:\n",
    "    f.visititems(extract_node_names)\n",
    "    pprint({'dataset names': nodes})\n",
    "    idx = 0\n",
    "    print(f'dataset {nodes[idx]} properties: ', f[nodes[idx]])\n",
    "    print(f'dataset {nodes[idx]} resolution: ', f[nodes[idx]].attrs['element_size_um'])\n",
    "    print(f'dataset {nodes[idx]} axes labels: ', f[nodes[idx]].attrs['DIMENSION_LABELS'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, we also need to visually inspect the resulting averaged volumes. We can use the napari viewer method provided in the *splitt3r* object. We limit to the first 42 blocks and pick the mean membrane channel for demonstration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(42))  # block indices\n",
    "images = ['memb/mean']  # 'chan/ch00'\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D splitt3r demo',\n",
    "    'crosshairs': [int(splitt3r.fullsize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clim': [0, 5000],\n",
    "}\n",
    "\n",
    "splitt3r.view(input=idxs, images=images, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a grip on how the dataset is layed out in blocks, we can alternate the colormaps of the blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate colormaps.\n",
    "cmaps = ['cyan', 'magenta', 'yellow']\n",
    "for i, lay in enumerate(splitt3r.viewer.layers):\n",
    "    lay.colormap = cmaps[i % len(cmaps)]\n",
    "lay.colormap = 'gray'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membrane enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before segmentation, we perform membrane enhancement.\n",
    "\n",
    "For the demo we do not want to be dependent on the third-party [ACME](https://wiki.med.harvard.edu/SysBio/Megason/ACME) software and provide the output that otherwise results from the ACME procedure. We split it into blocks, and write it as separate datasets in the same files as the channel data.\n",
    "\n",
    "Alternatively, if you have ACME installed and want to run it, set an `ACME` path environment variable or point `ACMEdir` to the directory with the binaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims_filepath = f'{dataset}_shading_stitching.ims'  # f'{dataset}_shading_stitching_biasfield.ims'\n",
    "image_in = ims_filepath\n",
    "\n",
    "max_workers = 5  # NB: ACME is memory-intensive\n",
    "\n",
    "from stapl3d.segmentation import enhance\n",
    "enhanc3r = enhance.Enhanc3r(image_in, parameter_file, prefix=dataset, max_workers=max_workers)\n",
    "enhanc3r.ACMEdir = os.environ.get('ACME')  # 'C:\\\\Users\\\\i.research_pc\\\\workspace\\\\ACME\\\\bin'  # \n",
    "\n",
    "if enhanc3r.ACMEdir:\n",
    "\n",
    "    # Perform membrane enhancement.\n",
    "    enhanc3r.run()\n",
    "\n",
    "else:\n",
    "\n",
    "    # Download precomputed membrane enhancement.\n",
    "    acme_filepath = f'{dataset}_shading_stitching_ACME.h5'\n",
    "    if not os.path.exists(acme_filepath):\n",
    "        url = 'https://surfdrive.surf.nl/files/index.php/s/oQcxIocFBkaXwJe/download'\n",
    "        urllib.request.urlretrieve(url, acme_filepath)\n",
    "\n",
    "    # Split into blocks\n",
    "    from stapl3d import blocks\n",
    "    for ids in ['memb/preprocess', 'memb/planarity']:\n",
    "        im_in = f'{acme_filepath}/{ids}'\n",
    "        splitt3r = blocks.Splitt3r(im_in, parameter_file, prefix=dataset, step_id='')\n",
    "        splitt3r.inputpaths['split']['data'] = im_in\n",
    "        splitt3r.output_ND = ids\n",
    "        splitt3r.volumes = {}  # FIXME: splitter entry is read from parameter_file despite <, step_id=''>\n",
    "        splitt3r.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We vizualize the membrane-enhanced volume with napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize viewer.\n",
    "idxs = list(range(42))  # block indices\n",
    "images = ['memb/planarity']\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D enhanc3r demo',\n",
    "    'crosshairs': [int(enhanc3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clim': [0, 0.05],\n",
    "}\n",
    "\n",
    "enhanc3r.view(input=idxs, images=images, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The segmentation is parallelized over the blocks we just created. Each of the 64 files is processed seperately.\n",
    "The segmentation routine is associated with a fair amount of steps and parameters. This list all the parameters specified in the yml-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['segmentation']['estimate'])  # TODO: need to preserve order of print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The blocks will processed in order according to the steps defined in the parameter file. Operations are listed below and step names have to be prefixed with these keywords.\n",
    "- *prep*: filtering of volumes\n",
    "- *mask*: compartment mask creation\n",
    "- *combine*: mask combination\n",
    "- *seed*: seed generation\n",
    "- *segment*: watershed segmentation\n",
    "- *filter*: size filtering and label masking\n",
    "\n",
    "For your own data, it is advised to start with tuning the following parameters to optimize segmentation:\n",
    "- mask_memb : threshold\n",
    "- mask_nucl : sauvola : window_size\n",
    "- mask_nucl : sauvola : threshold\n",
    "- mask_nucl : sauvola : absmin\n",
    "- seeds : peaks : window\n",
    "- seeds : peaks : window\n",
    "- segment : watershed : compactness\n",
    "- prep_memb : filter : sigma\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we calculate the segments for each block. Segmentation time of single block is in the minutes-range. The 106 x 240 x 240 blocksize (including the margin) will take ~1GB of memory per process. Please set the number of processes so that you will stay within RAM. `max_workers = 8` would be a fairly safe bet for modern systems; `max_workers = 0` results in using all available processors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.segmentation import segment\n",
    "\n",
    "max_workers = 0\n",
    "\n",
    "segment3r = segment.Segment3r(image_in, parameter_file, prefix=dataset, max_workers=max_workers)\n",
    "segment3r.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report pages (pdf) have been written to the *HFK16w/blocks/* directory. Let's look at one of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = 1\n",
    "# Get the outputpaths of the 'estimate' method for a block.\n",
    "_, opaths = segment3r.fill_paths('estimate', reps={'b': block_idx})\n",
    "# (Re)generate the report from the data and plot inline.\n",
    "segment3r.report(outputpath=None, ioff=False, outputs=opaths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From top to bottom, images are show for:\n",
    " - the smoothed DAPI and mean membrane channels\n",
    " - the nuclear mask and the membrane mask\n",
    " - the combined mask with detected peaks and overlaid on the distance transform image\n",
    " - the first and the final watershed results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the 'labels' argument to visualize masks and labels in napari. First, this overlays the membrane mask with the planarity volume for the top row of blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(8))  # block indices\n",
    "images = ['memb/planarity']\n",
    "labels = ['nucl/mask']\n",
    "\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D segment3r demo',\n",
    "    'crosshairs': [int(segment3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clim': {'memb/planarity': [0, 0.05]},\n",
    "    'opacity': {'nucl/mask': 0.5},\n",
    "}\n",
    "\n",
    "segment3r.view(input=idxs, images=images, labels=labels, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at the extracted segments for the block we view as a pdf report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['nucl/prep']\n",
    "labels = ['segm/labels']\n",
    "\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D segment3r demo',\n",
    "    'crosshairs': [int(segment3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clim': {'nucl/prep': [0, 20000]},\n",
    "    'opacity': {'segm/labels': 0.8},\n",
    "}\n",
    "\n",
    "segment3r.view(input=block_idx, images=images, labels=labels, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# zipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having parallelized the segmentation process for increased analysis speed and reduced memory footprint, the need arises to reassemble the blocks into a final combined segmentation volume without seams at the block boundaries. These seams are a consequence of trivial parallelization in processing the individual blocks (i.e. without communication between the processes). They manifest through partial cells lying on the block boundaries that have been assigned different labels in different blocks. Importantly, these doubly segmented cells may not perfectly match up over the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be demonstrated by loading the segmentation of the top two rows of blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment3r.view(input=list(range(16)), images=images, labels=labels, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These block-boundary-segments need to be resegmented in order to complete the accurate segmentation of the full dataset. We refer to this correct reassembly of the datablocks as ‘zipping’. In short, it consists of identifying the segments lying on the boundaries, removing them, and resegmenting that space. We aimed to design the procedure such that it requires minimal computational resources and expertise (fast, with a low memory footprint, and without the need for communication between processes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a one-liner for computing all the steps in the zip:\n",
    "```\n",
    "zipp3r.run()\n",
    "```\n",
    "which combines these three steps:\n",
    "```\n",
    "zipp3r.relabel()\n",
    "zipp3r.copyblocks()\n",
    "zipp3r.estimate()\n",
    "```\n",
    "\n",
    "For this demo, we will be much more verbose to illustrate the zipping process. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first perform a sequential relabeling of all the blocks to make each label unique.\n",
    "We copy the relabeled blocks to new datasets in the same file for writing the zip-results in-place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a convenience function that merges datablocks into a single volume and returns a single z-plane for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d import blocks\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "volumes = {\n",
    "    'memb/mean': {'format': 'h5', 'suffix': None},\n",
    "    'segm/labels': {'format': 'h5', 'suffix': None, 'is_labelimage': True},\n",
    "    'segm/labels_zip': {'format': 'h5', 'suffix': None, 'is_labelimage': True},\n",
    "    'segm/labels_zipmask': {'format': 'h5', 'suffix': None},\n",
    "}\n",
    "merg3r = blocks.Merg3r(image_in, parameter_file, prefix=dataset)\n",
    "merg3r._volumes = [{ids: vol} for ids, vol in volumes.items()]\n",
    "merg3r._init_paths_merger()\n",
    "\n",
    "\n",
    "def merge_and_slice_dset(merg3r, ids, slc=20):\n",
    "    \"\"\"Merge volume and return sliced data.\"\"\"\n",
    "\n",
    "    # Run the block merge.\n",
    "    merg3r.run()\n",
    "\n",
    "    # Get a slice of the merged data.\n",
    "    _, opaths = merg3r.fill_paths('merge')\n",
    "    im = Image(opaths[ids])\n",
    "    im.load()\n",
    "    im.slices[0] = slice(slc, slc + 1, 1)\n",
    "    data = im.slice_dataset()\n",
    "    im.close()\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting labels, we define a label shuffling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.segmentation import relabel_sequential\n",
    "from random import shuffle\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "def shuffle_labels(labels):\n",
    "    \"\"\"Shuffle labels in a volume.\"\"\"\n",
    "\n",
    "    labels = relabel_sequential(labels)[0]\n",
    "    ulabels = np.unique(labels[:])[1:]\n",
    "    relabeled = [l for l in range(0, len(ulabels))]\n",
    "    shuffle(relabeled)\n",
    "    labels = np.array([0] + relabeled)[labels]\n",
    "\n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check with the membrane mean blocks. This should output an image of 1408 x 1408."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = 'memb/mean'\n",
    "merg3r._volumes = [{ids: volumes[ids]}]\n",
    "merg3r._init_paths_merger()\n",
    "img = merge_and_slice_dset(merg3r, ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img, cmap='gray', vmax=5000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, we can show the labels with the seams before zipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = 'segm/labels_zip'\n",
    "merg3r._volumes = [{ids: volumes[ids]}]\n",
    "merg3r._init_paths_merger()\n",
    "labels = shuffle_labels(merge_and_slice_dset(merg3r, ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8, 8))\n",
    "plt.imshow(label2rgb(labels))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we set up the zipping estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_id = 'estimate'\n",
    "\n",
    "# write maxlabels to file\n",
    "outputs = zipp3r._prep_paths(zipp3r.outputpaths[step_id])\n",
    "maxlabelfile = outputs['maxlabelfile']\n",
    "kwargs = {}\n",
    "arglist = zipp3r._prep_step(step_id, kwargs)\n",
    "filepaths = zipp3r._get_filepaths(arglist)\n",
    "zipping.get_maxlabels_from_attribute(\n",
    "    filepaths,\n",
    "    zipp3r.ids_labels,\n",
    "    maxlabelfile,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the zipping procedure, we employ an order such that no blocks are handled concurrently. First, blocks with overlap in the Y-dimension are processed (odd and even zip-lines separately); then X-ziplines; then the corners where four datablocks overlap are resegmented. For demo purpose, we keep track of the output for each step and store it in `imgs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "imgs = []\n",
    "\n",
    "# Initialize arguments\n",
    "args = [filepaths, 0, [-1, -1, -1], maxlabelfile]\n",
    "\n",
    "# Resegment zip-lines in 4 groups:\n",
    "# horizontal/even, horizontal/odd, vertical/even, vertical/odd zip-lines.\n",
    "for axis, n_seams in zip([1, 2], zipp3r.seamgrid.shape):\n",
    "    n_proc = min(zipp3r._n_workers, int(np.ceil(n_seams / 2)))\n",
    "    for offset in [0, 1]:\n",
    "        zipp3r.compute_zip_step(\n",
    "            args, axis=axis,\n",
    "            starts=[offset, 0], stops=[n_seams, 1], steps=[2, 2],\n",
    "            n_proc=n_proc,\n",
    "        )\n",
    "        zipping.get_maxlabels_from_attribute(\n",
    "            filepaths,\n",
    "            zipp3r.ods_labels,\n",
    "            maxlabelfile,\n",
    "        )\n",
    "        imgs.append(merge_and_slice_dset(merg3r, 'segm/labels_zip'))\n",
    "\n",
    "# Resegment zip-quads in 4 groups:\n",
    "# even/even, even/odd, odd/even, odd/odd zip-line intersections\n",
    "for start_y in [0, 1]:\n",
    "    for start_x in [0, 1]:\n",
    "        stops = list(zipp3r.seamgrid.shape)\n",
    "        zipp3r.compute_zip_step(\n",
    "            args, axis=0,\n",
    "            starts=[start_y, start_x], stops=stops, steps=[2, 2],\n",
    "            n_proc=zipp3r._n_workers,\n",
    "        )\n",
    "        zipping.get_maxlabels_from_attribute(\n",
    "            filepaths,\n",
    "            zipp3r.ods_labels,\n",
    "            maxlabelfile,\n",
    "        )\n",
    "        imgs.append(merge_and_slice_dset(merg3r, 'segm/labels_zip'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 4, figsize=(24, 12))\n",
    "for img, ax in zip(imgs, axs.flat):\n",
    "    ax.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Newly processed zip-lines are assigned high labels indicated in yellow of the viridis colormap, nicely demonstrating the zipping process.\n",
    "\n",
    "<!---The zip-lines still have seams in the places where they intersect. Next we process zip-quads, in which the segments on these intersections are resegmented to finish the zip.-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compare the labels before and after the zip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = 'segm/labels_zip'\n",
    "merg3r._volumes = [{ids: volumes[ids]}]\n",
    "merg3r._init_paths_merger()\n",
    "labels_zipped = shuffle_labels(merge_and_slice_dset(merg3r, ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1, 2, figsize=(16, 32))\n",
    "for img, ax in zip([labels, labels_zipped], axs.flat):\n",
    "    ax.imshow(label2rgb(shuffle_labels(img)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the zip result with napari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idss = ['segm/labels', 'segm/labels_zip']\n",
    "\n",
    "merg3r = blocks.Merg3r(image_in, parameter_file, prefix=dataset)\n",
    "merg3r._volumes = [{ids: volumes[ids]} for ids in idss]\n",
    "merg3r._init_paths_merger()\n",
    "merg3r.run()\n",
    "\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D merg3r demo',\n",
    "    'crosshairs': [int(merg3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clims': [0, 1],\n",
    "    'opacity': 1,\n",
    "}\n",
    "\n",
    "filepath = merg3r.outputpaths['postprocess']['aggregate']\n",
    "merg3r.view(input=filepath, images=[], labels=idss, settings=viewer_settings)\n",
    "\n",
    "# NOTE: some new seams are created on the margins because the blocks of this demo are too small\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compartmental segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In STAPL-3D, we use rich multidimensional data to obtain a robust segmentation. We can also use the information we have to perform subcellular segmentation. Here, we split segments in nucleus and membrane subsegments such that we can specifically extract intensities from the appropriate voxels for the type of staining (nuclear or membranal). In addition, the subsegmentation opens up possibilities for defining compound features that inform on internal cell structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.segmentation import segment\n",
    "\n",
    "subsegment3r = segment.Subsegment3r(image_in, parameter_file, prefix=dataset)\n",
    "subsegment3r.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vols = [f'segm/labels_{vol}' for vol in ['full', 'nucl', 'memb']]\n",
    "merg3r = blocks.Merg3r(image_in, parameter_file, prefix=dataset)\n",
    "merg3r._volumes = [{vol: {'format': 'h5', 'suffix': None, 'is_labelimage': True}} for vol in vols]\n",
    "merg3r._init_paths_merger()\n",
    "merg3r.run()\n",
    "\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D merg3r demo',\n",
    "    'crosshairs': [int(merg3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "    'clims': [0, 1],\n",
    "    'opacity': 1,\n",
    "}\n",
    "\n",
    "filepath = merg3r.outputpaths['postprocess']['aggregate']\n",
    "merg3r.view(input=filepath, images=[], labels=vols, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stapl3d",
   "language": "python",
   "name": "stapl3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
