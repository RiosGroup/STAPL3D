{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAPL3D - PyTorch integration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Imports.\n",
    "import os\n",
    "\n",
    "projectdir = '/Users/michielkleinnijenhuis/PMCdata/1.projects/FGS'\n",
    "dataset = 'FGS_RL1_Exp002'\n",
    "\n",
    "datadir = os.path.join(projectdir, dataset)\n",
    "\n",
    "os.makedirs(datadir, exist_ok=True)\n",
    "os.chdir(datadir)\n",
    "f'working in directory: {os.path.abspath(\".\")}'\n",
    "parameter_file = f'{dataset}.yml'\n",
    "image_in = os.path.join(datadir, 'blocks')\n",
    "\n",
    "image_in = f'{datadir}/' + '{f}.czi'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We are taking the downsampled data => get info from blockfile, not czi\n",
    "\n",
    "blockdir = os.path.join(datadir, 'blocks')\n",
    "image_in = os.path.join(blockdir, '{f}.h5')\n",
    "\n",
    "from stapl3d.segmentation import segment\n",
    "segment3r = segment.Segment3r(image_in, parameter_file, prefix=dataset, step_id='segmentation_norm', datadir=datadir)  # datadir has to be specified as argument here, because the data is in blockdir\n",
    "segment3r.estimate()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Torch3r LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.deep_learning import unet\n",
    "torch3r = unet.Torch3r(image_in, parameter_file)\n",
    "torch3r.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch3r.view([0], images=['image_lr', 'image_lr_norm', 'memb/prob'], labels=['mask_lr', 'memb/pred'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep dataset on HPC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# ssh -i ~/.ssh/id_rsa_hpc -X mkleinnijenhuis@hpcs03.op.umcutrecht.nl\n",
    "# srun -c 1 --time 04:00:00 --mem 100G --pty bash\n",
    "# srun -c 4 --partition=gpu --gpus-per-node=RTX6000:1 --time 04:00:00 --mem 10G --pty bash\n",
    "# srun --partition=gpu --time 01:00:00 --mem 10G --pty bash\n",
    "\n",
    "# load STAPL3D paths\n",
    "source \"/hpc/pmc_rios/.stapl3d.ini\" && load_stapl3d_config\n",
    "\n",
    "# Specify dataset and move to it.\n",
    "projectdir='/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS'\n",
    "dataset='FGS_RL1_Exp002'\n",
    "load_dataset \"${projectdir}\" \"${dataset}\"\n",
    "\n",
    "# Specify parameter file and load into shell\n",
    "parfile=\"${dataset}.yml\"\n",
    "#[[ -f \"${parfile}\" ]] || init_dataset\n",
    "load_parameters \"${dataset}\" -v \"${parfile}\"\n",
    "\n",
    "# Set blockstems array parameter (it's length determines the number of parallel jobs.)\n",
    "unset blockstems\n",
    "blockstems=()\n",
    "for filename in `ls $datadir/blocks`; do\n",
    "    dstem=\"${filename%.*}\"\n",
    "    blockstems+=( \"$dstem\" )\n",
    "done\n",
    "echo \"${#blockstems[@]}\"\n",
    "\n",
    "# Generate segmentation script.\n",
    "dataset__alias='FGS002'\n",
    "image_in='blocks/{f}.h5'\n",
    "jid=h  # 'h' is for hold (dry-run); keep jid empty for direct submit\n",
    "submit $( generate_script segmentation estimate) $jid\n",
    "\n",
    "\n",
    "# NOTE: MANUAL ADAPTATIONS in in go_segmentation_estimate.py\n",
    "segment3r = segment.Segment3r('blocks/{f}.h5', \"FGS_RL1_Exp002.yml\", datadir='/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002')\n",
    "\n",
    "# NOTE: MANUAL ADAPTATIONS in in go_segmentation_estimate.sh\n",
    "#SBATCH --array=1-81:1\n",
    "\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submit Torch3r job on HPC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "dataset__alias='FGS002'\n",
    "image_in='blocks/{f}.h5'\n",
    "jid=\n",
    "submit $( generate_script torch train) $jid\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of files needed for Torch3r job submission:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FGS_RL1_Exp002.yml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "submit_defaults:\n",
    "    submit:\n",
    "        array: no\n",
    "        start: 1\n",
    "        step: 1\n",
    "        simul: 0\n",
    "        wtime: 01:00:00\n",
    "        mem: 60G\n",
    "        nodes: 1\n",
    "        tasks: 1\n",
    "        conda_env: stapl3d_torch\n",
    "\n",
    "segmentation:\n",
    "    submit:\n",
    "        array: block\n",
    "    estimate:\n",
    "        prep1:\n",
    "            ids_image: image_lr\n",
    "            ods_image: image_lr_lr\n",
    "            downsample:\n",
    "                factors:\n",
    "                    z: 1\n",
    "                    y: 5\n",
    "                    x: 5\n",
    "#        prep2:\n",
    "#            ids_image: image_lr_lr\n",
    "#            ods_image: image_lr_lr_norm\n",
    "#            norm:\n",
    "#                perc: [0, 99]\n",
    "\n",
    "torch:\n",
    "    train:\n",
    "        submit:\n",
    "            array: no\n",
    "            mem: 10G\n",
    "            wtime: 10:00:00\n",
    "            partition: gpu\n",
    "            gpus_per_node: RTX6000:1\n",
    "            conda_env: stapl3d_torch\n",
    "        ids_image: image_lr_norm\n",
    "        ids_labels: mask_lr\n",
    "        ods_image: ''\n",
    "        epochs: 500\n",
    "        test_every_n_epochs: 20\n",
    "        checkpoint_every_n_epochs: 500\n",
    "        #train_indices: [0, 1, 2]\n",
    "        #val_indices: [3, 4, 5]\n",
    "        save_images: true\n",
    "        augment:\n",
    "            - Flip: {'axis': 'z', 'p': 0.5}\n",
    "            - Flip: {'axis': 'y', 'p': 0.5}\n",
    "            - Flip: {'axis': 'x', 'p': 0.5}\n",
    "            - Rotate: {'angle_range': [-15, 15], 'axes': 'xy', 'p': 1.0}\n",
    "            #- RandomCrop: {'crop_shape': [32, 120, 120], 'p': 1.0}\n",
    "            - GaussianNoise: {'var_range': [0, 0.001], 'clip': true, 'p': 0.5}\n",
    "            - BrightnessNoise: {'val_range': [-0.1, 0.1], 'clip': true, 'p': 1.0}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go_FGS002_torch_train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "#SBATCH --job-name=go_FGS002_torch_train\n",
    "#SBATCH --partition=gpu\n",
    "#SBATCH --gpus-per-node=RTX6000:1\n",
    "#SBATCH --cpus-per-task=4\n",
    "#SBATCH --mem=10G\n",
    "#SBATCH --time=01:00:00\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --array=1-1:1\n",
    "#SBATCH --output=/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002/go_FGS002_torch_train.sh.o%A.%a\n",
    "#SBATCH --error=/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002/go_FGS002_torch_train.sh.e%A.%a\n",
    "\n",
    "TASK_ID=${SLURM_ARRAY_TASK_ID}\n",
    "idx=$((TASK_ID - 1))\n",
    "\n",
    "\n",
    "source /hpc/local/CentOS7/pmc_rios/projects/STAPL3D/stapl3d/pipelines/functions.sh\n",
    "load_dataset /hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS FGS_RL1_Exp002\n",
    "load_parameters FGS_RL1_Exp002 -v\n",
    "\n",
    "source /hpc/local/CentOS7/pmc_rios/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate stapl3d_torch\n",
    "\n",
    "python /hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002/go_FGS002_torch_train.py blocks/{f}.h5 FGS_RL1_Exp002.yml ${idx}\n",
    "conda deactivate\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go_FGS002_torch_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "image_in = sys.argv[1]\n",
    "parameter_file = sys.argv[2]\n",
    "if len(sys.argv) > 3:\n",
    "    idx = int(sys.argv[3])\n",
    "from stapl3d import stapl3d_torch\n",
    "#torch3r = stapl3d_torch.Torch3r(image_in, parameter_file)\n",
    "torch3r = stapl3d_torch.Torch3r(image_in, parameter_file, datadir='/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002')\n",
    "torch3r.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.segmentation import segment\n",
    "datadir = '/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002'\n",
    "image_in = 'blocks/{f}.h5'\n",
    "parameter_file = 'FGS_RL1_Exp002.yml'\n",
    "segment3r = segment.Segment3r(image_in, parameter_file, datadir=datadir)\n",
    "segment3r.estimate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import sys\n",
    "image_in = sys.argv[1]\n",
    "parameter_file = sys.argv[2]\n",
    "if len(sys.argv) > 3:\n",
    "    idx = int(sys.argv[3])\n",
    "\n",
    "from stapl3d.deep_learning import unet\n",
    "datadir = '/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002'\n",
    "image_in = 'blocks/{f}.h5'\n",
    "parameter_file = 'FGS_RL1_Exp002.yml'\n",
    "torch3r = unet.Torch3r(image_in, parameter_file, datadir=datadir)\n",
    "torch3r.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.segmentation import segment\n",
    "segment3r = segment.Segment3r('blocks/{f}.h5', \"FGS_RL1_Exp002.yml\", datadir='/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002')\n",
    "# 0 is broken\n",
    "for idx in range(2, 81):\n",
    "    segment3r.estimate(blocks=[idx])\n",
    "# 6 is broken\n",
    "for idx in range(7, 81):\n",
    "    segment3r.estimate(blocks=[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d import stapl3d_torch\n",
    "torch3r = stapl3d_torch.Torch3r('blocks/{f}.h5', \"FGS_RL1_Exp002.yml\", datadir='/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002')\n",
    "torch3r.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "\n",
    "from stapl3d import stapl3d_torch\n",
    "torch3r = stapl3d_torch.Torch3r('blocks/{f}.h5', \"FGS_RL1_Exp002.yml\", datadir='/hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002')\n",
    "torch3r.train()\n",
    "\n",
    "# show how much RAM the above code allocated and the peak usage\n",
    "current, peak =  tracemalloc.get_traced_memory()\n",
    "print(f\"{current/1024**2:0.0f}, {peak/1024**2:0.0f}\")\n",
    "tracemalloc.stop()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unzip tars snippet\n",
    "```\n",
    "for filename in `ls *.tar.bz2`; do\n",
    "    tar -xf $filename\n",
    "done\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard from HPC\n",
    "On HPC node:\n",
    "```\n",
    "conda activate stapl3d_torch\n",
    "tensorboard --port 6006 --host 0.0.0.0 --logdir /hpc/pmc_rios/mkleinnijenhuis/1.projects/FGS/FGS_RL1_Exp002/logs/tb &\n",
    "alias sg='squeue | grep gpu'\n",
    "```\n",
    "On local:\n",
    "```\n",
    "ssh -L6006:hpcs03.compute.hpc:6006 -X mkleinnijenhuis@hpcs03.op.umcutrecht.nl\n",
    "localhost:6006\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HPC env info\n",
    "```\n",
    "(stapl3d_torch) [mkleinnijenhuis@n0100 FGS_RL1_Exp002]$ python -m torch.utils.collect_env\n",
    "Collecting environment information...\n",
    "PyTorch version: 1.12.1\n",
    "Is debug build: False\n",
    "CUDA used to build PyTorch: Could not collect\n",
    "ROCM used to build PyTorch: N/A\n",
    "\n",
    "OS: CentOS Linux release 7.9.2009 (Core) (x86_64)\n",
    "GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)\n",
    "Clang version: Could not collect\n",
    "CMake version: version 2.8.12.2\n",
    "Libc version: glibc-2.17\n",
    "\n",
    "Python version: 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21)  [GCC 10.3.0] (64-bit runtime)\n",
    "Python platform: Linux-3.10.0-1160.25.1.el7.x86_64-x86_64-with-glibc2.17\n",
    "Is CUDA available: False\n",
    "CUDA runtime version: Could not collect\n",
    "GPU models and configuration: GPU 0: Quadro RTX 6000\n",
    "Nvidia driver version: 525.60.13\n",
    "cuDNN version: Probably one of the following:\n",
    "/usr/lib64/libcudnn.so.8.3.3\n",
    "/usr/lib64/libcudnn_adv_infer.so.8.3.3\n",
    "/usr/lib64/libcudnn_adv_train.so.8.3.3\n",
    "/usr/lib64/libcudnn_cnn_infer.so.8.3.3\n",
    "/usr/lib64/libcudnn_cnn_train.so.8.3.3\n",
    "/usr/lib64/libcudnn_ops_infer.so.8.3.3\n",
    "/usr/lib64/libcudnn_ops_train.so.8.3.3\n",
    "HIP runtime version: N/A\n",
    "MIOpen runtime version: N/A\n",
    "Is XNNPACK available: True\n",
    "\n",
    "Versions of relevant libraries:\n",
    "[pip3] numpy==1.21.0\n",
    "[pip3] numpydoc==1.5.0\n",
    "[pip3] torch==1.12.1\n",
    "[pip3] torchvision==0.13.0a0+8069656\n",
    "[conda] mkl                       2022.1.0           h84fe81f_915    conda-forge\n",
    "[conda] numpy                     1.21.0           py39hdbf815f_0    conda-forge\n",
    "[conda] numpydoc                  1.5.0              pyhd8ed1ab_0    conda-forge\n",
    "[conda] pytorch                   1.12.1          cpu_py39h3439074_1    conda-forge\n",
    "[conda] torchvision               0.13.0          cpu_py39hedfcc36_0    conda-forge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('stapl3d_torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e5a46e4cd65217fb3bd0e51bb5235db6a2d518d09294d55d828f5ae524bdc2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
