{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAPL-3D preprocessing demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the core components of the STAPL3D preprocessing pipeline: **z-stack shading** correction and **3D inhomogeneity** correction. \n",
    "\n",
    "If you did not follow the STAPL-3D README: please find STAPL-3D and the installation instructions [here](https://github.com/RiosGroup/STAPL3D) before doing this demo.\n",
    "\n",
    "Because STAPL-3D is all about big datafiles, we provide small cutouts and precomputed summary data that will be downloaded while progressing through the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some general settings and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qt gui for napari viewer\n",
    "%gui qt\n",
    "\n",
    "# Show all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Imports.\n",
    "import os\n",
    "import yaml\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from pprint import pprint\n",
    "\n",
    "# Yaml printing function.\n",
    "def yprint(ydict):\n",
    "    \"\"\"Print dictionary in yaml formatting.\"\"\"\n",
    "    print(yaml.dump(ydict, default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define where you want the data to be downloaded by changing *projectdir*; default is the current demo directory. The name of the dataset is *'HFK16w'* (for Human Fetal Kidney - 16 weeks). We create a directory for the dataset and jump to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = '.'\n",
    "dataset = 'HFK16w'\n",
    "\n",
    "datadir = os.path.join(projectdir, dataset)\n",
    "\n",
    "os.makedirs(datadir, exist_ok=True)\n",
    "os.chdir(datadir)\n",
    "f'working in directory: {os.path.abspath(\".\")}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define STAPL3D parameters preferably using a [yaml](https://yaml.org) parameter file. It has a simple structure and can be parsed in Python and `bash`. We will download the example, read it into a dictionary structure, list all entries and show the entry that contains information on the default directory structure for STAPL3D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_file = f'{dataset}.yml'\n",
    "\n",
    "# Download the yml-file.\n",
    "if not os.path.exists(parameter_file):\n",
    "    url = 'https://surfdrive.surf.nl/files/index.php/s/WZZB4GCBghexOiy/download'\n",
    "    urllib.request.urlretrieve(url, parameter_file)\n",
    "\n",
    "# Load parameter file.\n",
    "with open(parameter_file, 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "# List all entries.\n",
    "cfg.keys()\n",
    "\n",
    "# Inspect directory tree.\n",
    "yml_entry = 'dirtree'\n",
    "yprint(cfg[yml_entry])  # in yaml format\n",
    "pprint(cfg[yml_entry])  # as a dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shading correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shading correction (or flatfield correction) attempts to remove the intensity gradients that may be present in the xy-plane of the z-stacks that make up the dataset. These originate from imperfections in the microscope's optics and manifest as a grid over the assembled 3D volume. Because the shading is channel-specific, STAPL-3D estimates a 2D profile for each channel separately from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a 2-ch z-stack of data (106 x 1024 x 1024 x 2) in the data archive for demonstration purposes. These are two channels extracted from an 8-channel dataset of 262 stacks, i.e. ~0.1% of the data. The stack includes a nuclear channel (DAPI) and a membrane channel (NCAM1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the czi-file.\n",
    "\n",
    "czi_filepath = f'{dataset}.czi'\n",
    "if not os.path.exists(czi_filepath):\n",
    "    url = 'https://surfdrive.surf.nl/files/index.php/s/Ly85srzZmdWJCyJ/download'\n",
    "    urllib.request.urlretrieve(url, czi_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the parameters to the shading correction module in the yaml parameter file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameter file.\n",
    "yprint(cfg['shading'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that, in this example, we calculate the *median* value for z-stacks concatenated over X and Y, while masking any value < *1000*. We use the *20%* of planes that have the highest median intensities to calculate the 1D shading profile that is fit using a *3rd order* polynomial. The resulting files of this processing step are postfixed with *_shading* \n",
    "\n",
    "The estimation of the shading profile is done in parallel for channels. The number of concurrent processes can be set by specifying 'max_workers' in the yml-file, or as an argument. The default is to use the same number of processors as there are channels in the dataset--if available. \n",
    "\n",
    "Note that for cluster-deployment (SGE or SLURM), more specific configurations can be set in the yaml.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the shading estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.preprocessing import shading\n",
    "\n",
    "deshad3r = shading.Deshad3r(czi_filepath, parameter_file, prefix=dataset)\n",
    "deshad3r.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each channel, this will write the estimated shading profile as an image (.tif) and a processing report (.pdf), as well as the calculated medians (.npz), a logfile (.log) and parameters (.yml) to the *HFK16w/shading/* directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(os.listdir('shading'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the single stack these do not look great, because the algorithm needs multiple z-stacks to reliably estimate the shading profile. Therefore, we provide pre-calculated medians for the full 262-stack dataset (in *HFK16w/shading_full*) to demonstrate the expected output. First, let's plot the results for a single channel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract the shading_full directory.\n",
    "shading_dir = os.path.abspath('shading_full')\n",
    "zipfilepath = f'{shading_dir}.zip'\n",
    "\n",
    "if not os.path.exists(shading_dir):\n",
    "    url = 'https://surfdrive.surf.nl/files/index.php/s/yEqSRZdvQ9nYb7Q/download'\n",
    "    urllib.request.urlretrieve(url, zipfilepath)\n",
    "\n",
    "    with zipfile.ZipFile(zipfilepath, 'r') as zf:\n",
    "        zf.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " First, let's plot the results for a single channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and show the report of channel 0\n",
    "ch = 0\n",
    "\n",
    "dataset_full = '190910_RL57_FUnGI_16Bit_25x_125um_shading'\n",
    "filestem = os.path.join('shading_full', f'{dataset_full}_C{ch:03}')\n",
    "paths = {\n",
    "    'report': f'{filestem}.pdf',\n",
    "    'shading': f'{filestem}.tif',\n",
    "    'profile_X': f'{filestem}_X.npz',\n",
    "    'profile_Y': f'{filestem}_Y.npz',\n",
    "}\n",
    "deshad3r.report(outputpath=None, ioff=False, channel=ch, outputs=paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first row shows the result for concatenating the data over *X*, i.e. yielding a median value for each *yz*-coordinate. The left plot shows the medians of the planes (selected using a *quantile_threshold* parameter of 0.8) in rainbow colours. The right plot shows the normalized profile with confidence intervals as well as the normalized fit. The bottom left shows the median profile over *z*, with the selected planes indicated by tick marks. The bottom right image shows the 2D shading profile to use for correcting each plane in each z-stack of the channel. The red dashed traces indicates an -arbitrary- threshold to help with flagging potential issues with the data; the viridis colormap is also clipped to red  at this threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run it for all channnels, sending the output to pdf's in *HFK16w/shading_full*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in range(8):\n",
    "    filestem = os.path.join('shading_full', f'{dataset_full}_C{ch:03}')\n",
    "    paths = {\n",
    "        'report': f'{filestem}.pdf',\n",
    "        'shading': f'{filestem}.tif',\n",
    "        'profile_X': f'{filestem}_X.npz',\n",
    "        'profile_Y': f'{filestem}_Y.npz',\n",
    "    }\n",
    "    deshad3r.report(outputpath=paths['report'], ioff=True, channel=ch, outputs=paths)\n",
    "\n",
    "# Merge the pdfs into one file.\n",
    "deshad3r.inputpaths['postprocess']['report'] = os.path.join(shading_dir, f'{dataset_full}_C???.pdf')\n",
    "deshad3r.outputpaths['postprocess']['report'] = os.path.join(shading_dir, f'{dataset_full}.pdf')\n",
    "deshad3r.postprocess()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you plan to use your own imaging data, we stitch in the proprietary Zeiss Zen or Arivis software packages. Please stitch and then convert the result to an Imaris or STAPL-3D file-format. For the bias field estimation demo below, we provide a downsampled image of the stitching result in hdf5 format. For the segmentation demo, we provide a cutout of the fully preprocessed file in Imaris format: *HFK16w_shading_stitching_biasfield.ims*. A free viewer for these data can be downloaded [here](https://imaris.oxinst.com/imaris-viewer). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide an interface to Fiji BigStitcher in beta. Provide the path to FIJI as an environment variable 'FIJI' or directly below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from stapl3d.preprocessing import stitching\n",
    "\n",
    "stitch3r = stitching.Stitch3r(czi_filepath, parameter_file, prefix=dataset)\n",
    "\n",
    "if not os.environ.get('FIJI'):\n",
    "    stitch3r.FIJI = '/Applications/Fiji.app/Contents/MacOS/ImageJ-macosx'\n",
    "\n",
    "stitch3r.run()  # NOTE/FIXME: in the 1-stack example manual copy steps are needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhomogeneity correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next correct the stitched file for inhomogeneities such as depth attenuation and uneven penetration of clearing agents and antibodies. This is done using the *N4* algorithm ([Tustison et al., 2010](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3071855) as implemented in simpleitk) on a downsampled image. For this demo, we provide the downsampled data in an hdf5 file.\n",
    "\n",
    "We download the data, use the STAPL-3D Image class to get some info about this image, and display the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stitch_stem = f'{dataset}_shading_stitching'\n",
    "bfc_filepath = f'{stitch_stem}.h5'\n",
    "\n",
    "# Download the hdf5-file.\n",
    "if not os.path.exists(bfc_filepath):\n",
    "    url = 'https://surfdrive.surf.nl/files/index.php/s/WkMMCW5e4wgNUgb/download'\n",
    "    urllib.request.urlretrieve(url, bfc_filepath)\n",
    "\n",
    "# Print image info.\n",
    "from stapl3d import Image\n",
    "image_in = '{}/data'.format(bfc_filepath)\n",
    "im = Image(image_in)\n",
    "im.load(load_data=False)\n",
    "props = im.get_props()\n",
    "im.close()\n",
    "\n",
    "pprint(props)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image dimensions are *zyxc* = *106 x 263 x 249 x 8* with voxels of *1.2 x 21.3 x 21.3* $\\mu$m. This is a good size for estimating the slow variations over the volume. Default parameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['biasfield']['estimate'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `n_iterations`, `n_fitlevels` and `n_bspline_cps` are passed to the [ITK-filter](https://simpleitk.org/doxygen/latest/html/classitk_1_1simple_1_1N4BiasFieldCorrectionImageFilter.html). On workstations, the `tasks` parameter will set the number of processors ITK will use. \n",
    "(Note that for HPC cluster deployment, there is more control: channels are distributed over separate jobs, and the number of threads used for each channel can be set separately.)\n",
    "\n",
    "If an imaris pyramid image is provided, data will be taken at `resolution_level` and further downsampled with `downsample_factors`. Because the hdf5 file already contains downsampled data, we set `downsample_factors` to unitary.\n",
    "\n",
    "<!-- \n",
    "To use a mask in the estimation, the `mask` input can either be \n",
    " - set to `True`, in which case the path defaults to `{dataset}{cfg['mask']['postfix']}.h5/mask`\n",
    " - contain the path to a mask image (in which background should be `0`).\n",
    " The mask image is expected to be the same size as the input image, i.e. it will also be downsampled with `downsample_factors`. -->\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.preprocessing import biasfield\n",
    "\n",
    "homogeniz3r = biasfield.Homogeniz3r(czi_filepath, parameter_file, prefix=dataset)\n",
    "homogeniz3r.estimate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the reports to a single pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeniz3r.postprocess()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we (re)generate the bias field correction report of a single channel to inspect the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and show the report of a single channel\n",
    "ch = 3\n",
    "_, opaths = homogeniz3r.fill_paths('estimate', reps={'c': ch})\n",
    "homogeniz3r.report(outputpath=None, ioff=False, channel=ch, outputs=opaths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left column shows orthogonal sections of the downsampled dataset for the uncorrected (top) and corrected data (middle) as well as the estimated bias field (bottom). Plotted on the left and top of the images are profiles of the median values over the three axes. The right column offers a closer comparison of the profiles (*mean + SD*) for the corrected (green) vs uncorrected (red) data. The bias field correction yields a much flatter profile for *z*, as well as *xy*. Low-frequency inhomogeneities are removed, while the detail of the specific staining is retained in the corrected data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the estimation with a more reasonable number of iterations (N=50). This will take a lot longer, therefore we run it for a single channel. It will overwrite the data for the specified channel generated in the previous test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homogeniz3r.channels = [ch]  # only estimate the specified channel\n",
    "homogeniz3r.n_iterations = 50  # override the yaml-defined parameter\n",
    "homogeniz3r.estimate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compare the report for the new estimation using appropriate number of iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and show the report of channel \n",
    "_, opaths = homogeniz3r.fill_paths('estimate', reps={'c': ch})\n",
    "homogeniz3r.report(outputpath=None, ioff=False, channel=ch, outputs=opaths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that above, we only estimated the inhomogeneities at a low resolution. To apply the estimation to a full-resolution dataset and generate a file that merges all channels in a single (symlinked) hdf5-file, use ```homogeniz3r.apply()``` and ```homogeniz3r.postprocess()```. Or ```homogeniz3r.run()``` to execute all steps in a single call.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to the static reports, we can explore the results in ND using napari.\n",
    "- Ctrl/Cmd-E to roll axes\n",
    "- Ctrl/Cmd-G to toggle overlay / side-by-side view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['data', 'corr', 'bias']\n",
    "\n",
    "homogeniz3r.view(opaths['file'], images)\n",
    "\n",
    "homogeniz3r.viewer.title = 'STAPL3D homogeniz3r demo'\n",
    "\n",
    "axes = homogeniz3r.viewer.axes\n",
    "dims = homogeniz3r.viewer.dims\n",
    "cam = homogeniz3r.viewer.camera\n",
    "layers = homogeniz3r.viewer.layers\n",
    "\n",
    "# Move scrollbars to centreslices.\n",
    "cslcs = [int(s / 2) for s in props['shape'][:3]]\n",
    "dims.current_step = cslcs\n",
    "\n",
    "# Show axes.\n",
    "axes.visible = True\n",
    "\n",
    "# Rescale the z-axis for better appreciation in the xz and yz views\n",
    "orig_scale = [s for s in layers['data'].scale]  # keep for convenience\n",
    "for lay in layers:\n",
    "    lay.scale = [1, 1, 1]\n",
    "\n",
    "# Set equal contrast limits for uncorrected and corrected volumes.\n",
    "clim = [0, 10000]\n",
    "layers['data'].contrast_limits = layers['corr'].contrast_limits = clim\n",
    "\n",
    "# Toggle bias off for now\n",
    "layers['bias'].visible = False\n",
    "layers['bias'].colormap = 'magma'\n",
    "\n",
    "# Ctrl/Cmd-E to roll axes\n",
    "# dims.order = (2, 0, 1)\n",
    "\n",
    "# Ctrl/Cmd-G to toggle overlay / side-by-side view\n",
    "# homogeniz3r.viewer.grid.enabled = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the bias landscape\n",
    "dims.ndisplay = 3\n",
    "dims.order = (0, 1, 2)\n",
    "\n",
    "cam.zoom = 2.0\n",
    "cam.center = cslcs\n",
    "cam.angles = (-10, -10, 155)\n",
    "\n",
    "layers['bias'].visible = True\n",
    "layers['bias'].contrast_limits = [0.8, 2.0]\n",
    "layers['bias'].colormap = 'magma'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of the guided look at the single channel, the results of all channels can be loaded as 4D images. Note that when you followed this tutorial exactly only one channel was processed with the right parameters and shows differences between corrected and non-corrected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer_settings = {\n",
    "    'title': 'STAPL3D homogeniz3r demo',\n",
    "    'crosshairs': [int(s / 2) for s in props['shape'][:4]],\n",
    "    'axes_visible': False,\n",
    "    'clim': [0, 10000],\n",
    "}\n",
    "homogeniz3r.view(images=['data', 'corr'], settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stapl3d",
   "language": "python",
   "name": "stapl3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
