{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAPL-3D organoid segmentation demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the core components of the STAPL3D organoid pipeline: **...** and **...**.\n",
    "\n",
    "If you did not follow the STAPL-3D README: please find STAPL-3D and the installation instructions [here](https://github.com/RiosGroup/STAPL3D) before doing this demo.\n",
    "\n",
    "Because STAPL-3D is all about big datafiles, we provide small cutouts and precomputed summary data that will be downloaded while progressing through the notebook."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some general settings and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Imports.\n",
    "import os\n",
    "import yaml\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from pprint import pprint\n",
    "\n",
    "# Yaml printing function.\n",
    "def yprint(ydict):\n",
    "    \"\"\"Print dictionary in yaml formatting.\"\"\"\n",
    "    print(yaml.dump(ydict, default_flow_style=False))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define where you want the data to be downloaded by changing *projectdir*; default is the current demo directory. The name of the dataset is *'FGS_RL1_Exp001'*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = os.path.abspath('.')\n",
    "\n",
    "dataset = 'FGS_RL1_Exp001'\n",
    "datadir = os.path.join(projectdir, dataset)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provided a ...\n",
    "> REPLACE: preprocessed data cutout in the Imaris v5.5 file format. which is an hdf5 file with 5 dimensions (a free [Imaris Viewer](https://imaris.oxinst.com/imaris-viewer) is available; and the file format can be inspected with [HDFview](https://www.hdfgroup.org/downloads/hdfview/) or with `h5ls` or `h5py`.\n",
    "\n",
    "We download the file and name it according to the default STAPL-3D pipeline conventions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipfilepath = os.path.join(projectdir, f'{dataset}.zip')\n",
    "\n",
    "# TODO: upload and create public link\n",
    "# TODO: all these files are hosted on my surfdrive: need to transfer ownership\n",
    "#if not os.path.exists(zipfilepath):\n",
    "#    url = '<public_link>/download'\n",
    "#    urllib.request.urlretrieve(url, zipfilepath)\n",
    "\n",
    "# TODO: rename in zipfile to *'FGS_RL1_Exp001'*\n",
    "if not os.path.exists(datadir):\n",
    "    with zipfile.ZipFile(zipfilepath, 'r') as zf:\n",
    "        zf.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of the extracted dataset is *'FGS_RL1_Exp001'*. Jump to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'working in directory: d:\\\\mkleinnijenhuis\\\\STAPL3D\\\\demos\\\\FGS_RL1_Exp001'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(datadir)\n",
    "f'working in directory: {os.path.abspath(\".\")}'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define STAPL3D parameters preferably using a [yaml](https://yaml.org) parameter file. It has a simple structure and can be parsed in Python and `bash`. We will download the example, read it into a dictionary structure and list all the main entries in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('FGS_RL1_Exp001.yml', <http.client.HTTPMessage at 0x27c9f9422e0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataset', 'biasfield', 'splitter', 'segmentation_prep', 'segmentation_edt', 'segmentation', 'segmentation_small', 'segmentation_medium', 'segmentation_large', 'segmentation_filter', 'segmentation_plot', 'features', 'backproject'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_file = f'{dataset}.yml'\n",
    "\n",
    "# Download the yml-file.\n",
    "if not os.path.exists(parameter_file):\n",
    "    url = 'https://surfdrive.surf.nl/files/index.php/s/WknwEh5etW9IHWZ/download'\n",
    "    urllib.request.urlretrieve(url, parameter_file)\n",
    "\n",
    "# Load parameter file.\n",
    "with open(parameter_file, 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "# List all entries.\n",
    "cfg.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import napari\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "from stapl3d import Image, blocks, backproject\n",
    "from stapl3d.segmentation import segment, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the input using a format specifier *'{f}.czi'*, which will select all files with the czi extension in the data directory.\n",
    "In this example, there are 6 files in the dataset. Therefore, we set the maximaum number of simultaneous workers to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filespec_raw = '{f}.czi'\n",
    "\n",
    "max_workers = 6\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitt3r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For organoid segmentation, we calculate the mean over channels in order to achieve maximal coverage and optimal signal for segmentation. The parameter file specifies the volumes to generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'volumes': {'mean': {}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['splitter']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  splitter:blockinfo in 6 jobs over 6 workers\n",
      "Running  splitter:split in 6 jobs over 6 workers\n"
     ]
    }
   ],
   "source": [
    "from stapl3d import blocks\n",
    "\n",
    "splitt3r = blocks.Splitt3r(filespec_raw, parameter_file, max_workers=max_workers)\n",
    "splitt3r.run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the *'blocks'* directory, with hdf5-files having the same names as the czi-files, but the *'.h5'* extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FGS_RL1_Exp001-2_Img020_34T.h5',\n",
       " 'FGS_RL1_Exp001-2_Img024_36T.h5',\n",
       " 'FGS_RL1_Exp001-2_Img040_MDO4.h5',\n",
       " 'FGS_RL1_Exp001-3_Img003_10T.h5',\n",
       " 'FGS_RL1_Exp001-3_Img006_13T.h5',\n",
       " 'FGS_RL1_Exp001-3_Img026_169M.h5']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths = os.listdir('blocks')\n",
    "filepaths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These now each contain 3D volume named *'mean'* and a group *'block_info'* containing some metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['block_info', 'mean']>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"mean\": shape (50, 1024, 1024), type \"<u2\">"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File(os.path.join('blocks', filepaths[0]))\n",
    "f.keys()\n",
    "f['mean']\n",
    "f.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the mean volumes with the napari viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idxs = list(range(len(splitt3r.filepaths)))\n",
    "splitt3r.view(block_idxs, images=['mean'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment3r"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of the demo, we separate the steps in the segmentation over a number of parameter file entries: *segmentation_prep*, *segmentation_edt*, *segmentation* and *segmentation_filter*. We select steps specifying the 'step_id' argument to the segmenter, e.g.:\n",
    "```\n",
    "segment3r = segment.Segment3r(filespec_raw, parameter_file, max_workers=max_workers, step_id='segmentation_prep')\n",
    "```\n",
    "and then run it calling\n",
    "```\n",
    "segment3r.estimate()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep\n",
    "\n",
    "In the first step,\n",
    "1. a clipping mask is generated\n",
    "2. the data is smoothed\n",
    "3. an organoid mask is generated\n",
    "\n",
    "Furthermore,\n",
    "\n",
    "4. the data is downsampled and then smoothed\n",
    "5. an organoid mask is generated at the lower resolution.\n",
    "\n",
    "The associated parameters are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.\n",
      "mask_clip:\n",
      "  ids_image: mean\n",
      "  ods_mask: clip\n",
      "  threshold: 65000\n",
      "\n",
      "2.\n",
      "prep_dset:\n",
      "  filter:\n",
      "    inplane: false\n",
      "    sigma: 2.5\n",
      "    type: gaussian\n",
      "  ids_image: mean\n",
      "  ods_image: prep\n",
      "\n",
      "3.\n",
      "mask_dset:\n",
      "  ids_image: prep\n",
      "  ods_mask: mask\n",
      "  otsu:\n",
      "    perc_range:\n",
      "    - 0\n",
      "    - 99\n",
      "\n",
      "4.\n",
      "prep_dset_ds:\n",
      "  downsample:\n",
      "    factors:\n",
      "      x: 5\n",
      "      y: 5\n",
      "      z: 1\n",
      "    ods: mean_ds\n",
      "  filter:\n",
      "    inplane: false\n",
      "    sigma: 2.5\n",
      "    type: gaussian\n",
      "  ids_image: mean\n",
      "  ods_image: prep_ds\n",
      "\n",
      "5.\n",
      "mask_dset_ds:\n",
      "  dilate: {}\n",
      "  fill: 2D\n",
      "  ids_image: prep_ds\n",
      "  ods_mask: mask_ds\n",
      "  otsu:\n",
      "    perc_range:\n",
      "    - 0\n",
      "    - 99\n",
      "  size_filter_vx: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (k, v) in enumerate(cfg['segmentation_prep']['estimate'].items()):\n",
    "    print(f'{i+1}.')\n",
    "    yprint({k: v})\n",
    "\n",
    "# FIXME: mask_dset_ds is not correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment3r = segment.Segment3r(filepath_raw, filepath_par, max_workers=max_workers, step_id='segmentation_prep')\n",
    "segment3r.estimate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idxs = [0]\n",
    "images = ['mean', 'prep', 'mean_ds', 'prep_ds']\n",
    "labels = ['clip', 'mask', 'mask_ds']\n",
    "segment3r.view(block_idxs, images, labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the distance transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment3r = segment.Segment3r(filepath_raw, filepath_par, max_workers=max_workers, step_id='segmentation_edt')\n",
    "segment3r.estimate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idxs = [0]\n",
    "images = ['prep_ds', 'mask_ds_edt']\n",
    "labels =  ['mask_ds', 'blobs_ds_label']\n",
    "segment3r.view(block_idxs, images, labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment3r = segment.Segment3r(filepath_raw, filepath_par, max_workers=max_workers, step_id='segmentation')\n",
    "segment3r.estimate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idxs = [0]\n",
    "images = ['prep_ds', 'mask_ds_edt']\n",
    "labels = ['blobs_ds_label', 'mask_ds_seeds', 'blobs_ds_raw']\n",
    "segment3r.view(block_idxs, images, labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postprocess the organoid segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment3r = segment.Segment3r(filepath_raw, filepath_par, max_workers=max_workers, step_id='segmentation_filter')\n",
    "segment3r.estimate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idxs = [0]\n",
    "images = ['mean', 'prep']\n",
    "labels = ['blobs_expand', 'mask', 'blobs', 'clip', 'blobs_clip', 'blobs_clip_deleted']\n",
    "segment3r.view([0], images, labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a report for each stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment3r = segment.Segment3r(filepath_raw, filepath_par, max_workers=max_workers, step_id='segmentation_plot')\n",
    "segment3r.estimate()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the reports to the logs directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment3r.postprocess()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stapl3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f39f99575e7f05b37a5c88d5bf5acd2ff274d6a564902f1d28d2fa97515657be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
