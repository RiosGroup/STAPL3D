{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAPL-3D feature extraction demo\n",
    "\n",
    "This notebook demonstrates the core components of the STAPL-3D feature extraction module.\n",
    "\n",
    "If you did not follow the STAPL-3D README: please find STAPL-3D and the installation instructions [here](https://github.com/RiosGroup/STAPL3D) before doing this demo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some general settings and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Imports.\n",
    "import os\n",
    "import yaml\n",
    "import urllib.request\n",
    "from pprint import pprint\n",
    "\n",
    "# Yaml printing function.\n",
    "def yprint(ydict):\n",
    "    \"\"\"Print dictionary in yaml formatting.\"\"\"\n",
    "    print(yaml.dump(ydict, default_flow_style=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define where you want the data to be downloaded by changing *projectdir*; default is the current demo directory. The name of the dataset is *'HFK16w'* (for Human Fetal Kidney - 16 weeks). We create a directory for the dataset and jump to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectdir = '.'\n",
    "dataset = 'HFK16w'\n",
    "\n",
    "datadir = os.path.join(projectdir, dataset)\n",
    "\n",
    "os.makedirs(datadir, exist_ok=True)\n",
    "os.chdir(datadir)\n",
    "f'working in directory: {os.path.abspath(\".\")}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define STAPL3D parameters preferably using a [yaml](https://yaml.org) parameter file. It has a simple structure and can be parsed in Python and `bash`. We will download the example, read it into a dictionary structure and list all the main entries in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_file = f'{dataset}.yml'\n",
    "\n",
    "# Download the yml-file.\n",
    "if not os.path.exists(parameter_file):\n",
    "    url = 'https://surfdrive.surf.nl/files/index.php/s/SAVgQDPwM4XsLlC/download'\n",
    "    urllib.request.urlretrieve(url, parameter_file)\n",
    "\n",
    "# Load parameter file.\n",
    "with open(parameter_file, 'r') as ymlfile:\n",
    "    cfg = yaml.safe_load(ymlfile)\n",
    "\n",
    "# List all entries.\n",
    "cfg.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking and distance to edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define where the dataset can be found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_in = f'{dataset}_shading_stitching.ims'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example kidney dataset, we use a distance-to-edge feature that is informative for the spatial aspects of the dataset. In particular, developmentally early structures are found in the periphery, while fully formed nephrons will be found nearer the center of the sample. Therefore, we use a distance transform on the sample mask to create a volume that indicates this distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['mask'])  # in yaml format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input will be smoothed with a 48 um kernel. Slicewise thresholds are generated at 1/5 of the median value of the slice intensities, with a minimum of 2000. The calculation of the distance-to-edge volume is switched on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.preprocessing import masking\n",
    "\n",
    "mask3r = masking.Mask3r(image_in, parameter_file, prefix=dataset)\n",
    "mask3r.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the report and the volumes to validate the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Re)generate the report from the data and plot inline.\n",
    "ipaths, opaths = mask3r.fill_paths('postprocess')\n",
    "mask3r.report(outputpath=None, ioff=False, inputs=ipaths, outputs=opaths)\n",
    "\n",
    "# Initialize viewer.\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D mask3r demo',\n",
    "    'axes_visible': False,\n",
    "    'clim': {'mean': [0, 6000], 'smooth': [0, 6000]},\n",
    "    'opacity': {'mask': 0.5},\n",
    "    }\n",
    "mask3r.view(settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The STAPL-3D feature extraction module offers fast extraction of features from large amounts of data. We create a feature table for each datablock using parallel processing, then combine these feature tables while filtering out doubles of the segments that are represented in multiple datablocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We supply the the following information to the feature extractor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['features']['estimate'])  # in yaml format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We specify names for the 8 channels to appear in the columns of the feature csv output.\n",
    "- We extract the features from the three separate compartments we have segmented. They are named 'full', 'memb' and 'nucl' and are specified as key-value pairs where the value is the internal path of the hdf5 dataset of the blockfiles.\n",
    "- We provide 'dist_to_edge' as an additional input to extract the values of this volume at the centroids of the segments. If the dist-to-edge volume has been generated from a downsampled image, the downsample factors need to be provided.\n",
    "- Morphological and intensity features are chosen by either a predefined feature set ('none', 'minimal', 'medium', 'maximal') or by providing lists of features (https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.regionprops)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the feature generator and show the chosen feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d.segmentation import features\n",
    "from importlib import reload\n",
    "reload(features)\n",
    "\n",
    "featur3r = features.Featur3r(image_in, parameter_file, prefix=dataset)\n",
    "featur3r.morphological_features\n",
    "featur3r.intensity_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all predefined features sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fset in ('none', 'minimal', 'medium', 'maximal'):\n",
    "    featur3r.morphological_features = featur3r.intensity_features = fset\n",
    "    featur3r.set_feature_set()\n",
    "    print(f'Name:\\n\\t {fset}')\n",
    "    print(f'Morphological:\\n\\t {featur3r.morphological_features}')\n",
    "    print(f'Intensity:\\n\\t {featur3r.intensity_features}\\n')\n",
    "\n",
    "# Revert to 'medium'\n",
    "featur3r.morphological_features = featur3r.intensity_features = 'medium'\n",
    "featur3r.set_feature_set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the demo, we set the extractor to create the features of the first 5 blocks and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featur3r.blocks = list(range(5))\n",
    "featur3r.estimate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A csv is generated for each block and segmented compartment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Show some of the files.\n",
    "filelist = glob(os.path.join(os.path.abspath('.'), 'blocks', f'{dataset}_blocks_B*.csv'))\n",
    "filelist.sort()\n",
    "filelist[:9]\n",
    "\n",
    "# Show one of the dataframes.\n",
    "df = pd.read_csv(filelist[0], index_col='label', header=0)\n",
    "df.describe()\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a single cell x feature matrix, we use the `postprocess` function to collate all the cells in the blocks. In this process we can also perform selection features as well as simple filtering of cells according to thresholding of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yprint(cfg['features']['postprocess'])  # in yaml format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featur3r.postprocess()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataframe.\n",
    "inpath = featur3r.outputpaths['postprocess']['feature_csv']\n",
    "df = pd.read_csv(inpath, index_col='label', header=0)\n",
    "df.describe()\n",
    "df.columns\n",
    "\n",
    "# Plot histograms of intensity features.\n",
    "cols = [col for col in df.columns if 'intensity' in col]\n",
    "df.hist(column=cols, bins=100, layout=(4, 2), figsize=(16, 16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprojected visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stapl3d import backproject\n",
    "\n",
    "backproject3r = backproject.Backproject3r(image_in, parameter_file, prefix=dataset)\n",
    "backproject3r.backproject()\n",
    "backproject3r.postprocess()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['area_nucl', 'SIX2_mean_intensity_nucl']\n",
    "labels = ['label', 'block']\n",
    "\n",
    "viewer_settings = {\n",
    "    'title': 'STAPL3D backproject3r demo',\n",
    "    'crosshairs': [int(backproject3r.blocksize[dim] / 2) for dim in 'zyx'],\n",
    "    'axes_visible': False,\n",
    "}\n",
    "\n",
    "filepath = backproject3r.outputpaths['postprocess']['aggregate']\n",
    "backproject3r.view(input=filepath, images=images, labels=labels, settings=viewer_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stapl3d",
   "language": "python",
   "name": "stapl3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
